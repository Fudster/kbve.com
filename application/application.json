[{"id":"android.mdx","slug":"android","body":"\n\n## ADB Cheatsheet\n\n### Device Commands\n\n- `adb devices` - List all connected devices.\n  - `adb devices -l` - Query additional information from devices.\n  - `adb get-state` - Information on the device state.\n  - `adb get-serialno` - Query the device serial number.\n- `adb root` - Launch module adbd with root permission.\n  - Error 1: `adbd cannot run as root in production builds`\n    - Resolution:\n- `adb start-server` - Start the adb server.\n- `adb kill-server` - Terminate the adb server.\n- `adb reboot` - Restart the current device.\n- `adb help` - Display additional information.\n\n### Shell\n\n- `adb shell` - Launch the shell terminal for the device.\n- `adb -s $deviceString $deviceCommand` - Send the $deviceCommand to a specific device named $deviceString\n- `adb shell pwd` - Command to list current directory.\n- `adb shell ls` - Command to list all the directory contents of the device.\n  - `adb shell ls -s` - Additional size information.\n  - `adb shell ls -R` - Recursion of the folders.\n- `adb shell netstat` - Query the TCP information\n- `adb shell dumpsys` - An android tool that dumps information related to system services.\n  - `adb shell dumpsys iphonesybinfo` - Query the IMEI information.\n  - `adb shell dumpsys battery` - Query battery information.\n    - `adb shell dumpsys battery set level $v` - Device battery level from 0 to 100.\n    - `adb shell dumpsys battery reset` - Reset the device battery.\n  - `adb shell dumpsys activity $package` - Query activity of package.\n- `adb shell pm list features` - Query device features.\n- `adb shell service list` - Query device services.\n- `adb shell wm` - ◈Null\n  - `adb shell wm size` - Current device screen resolution.\n    - `adb shell wm size $WxH` - Change device screen resolution.\n    - `adb shell wm size reset` - Reset device screen resolution.\n  - `adb shell wm density` - ◈Null\n    - `adb shell wm density reset` - Reset device density.\n- `adb shell ps` - Query process status on the device.\n\n### Key Events\n\n- Koltin: `open class KeyEvent: InputEvent, Parcelable`\n- Java: `pulibc class KeyEvent extends InputEvent implements Parcelable`\n- Android Key Events - A quick breakdown for each event and how the operating system handles them.\n- `adb shell input keyevent`\n  - `adb shell input keyevent 0` - ◈Keycode 0\n  - `adb shell input keyevent 1` - Soft Left\n  - `adb shell input keyevent 2` - Soft Right\n  - `adb shell input keyevent 3` - Home Button Event.\n  - `adb shell input keyevent 4` - Back Button Event.\n  - `adb shell input keyevent 5` - Call Event.\n  - `adb shell input keyevent 6` - End Call / Hangup Event.\n  - Events 7 to 18 are generic cell phone events.\n    - `adb shell input keyevent 7` - Keycode 0\n    - `adb shell input keyevent 8` - Keycode 1 aka Number 1\n    - `adb shell input keyevent 9` - Keycode 2 aka Number 2\n    - `adb shell input keyevent 10` - Keycode 3 aka Number 3\n    - `adb shell input keyevent 11` - Keycode 4 aka Number 4\n    - `adb shell input keyevent 12` - Keycode 5 aka Number 5\n    - `adb shell input keyevent 13` - Keycode 6 aka Number 6\n    - `adb shell input keyevent 14` - Keycode 7 aka Number 7\n    - `adb shell input keyevent 15` - Keycode 8 aka Number 8\n    - `adb shell input keyevent 16` - Keycode 9 aka Number 9\n    - `adb shell input keyevent 17` - STAR Key\n    - `adb shell input keyevent 18` - Pound Key\n","collection":"application","data":{"title":"Android","description":"Android is an open source operating system based off of linux.","tags":["technology","android","debug","mobile"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1607252650355-f7fd0460ccdb?fit=crop&w=1400&h=700&q=75"}},{"id":"ansible.mdx","slug":"ansible","body":"\n## Ansible\n\n- Automation software that enables `IaC` - also known as, infrastructure as code, thus allowing user to provision, configure, deploy and secure a whole array of software, applications and machines.\n\n## Ansible Cheatsheet\n\n- Commands that will make it easier operate ansible scripts / playbooks. This cheatsheet is still a work-in-progress.\n\n## Cheatsheet\n\n- Ansible cheatsheet\n\n## Playbook\n\n- Ansible Playbook\n\n## AWX\n\nAWX is a web-base RESTFul API and task engine that operates on top of Ansible, thus enabling you to automate certain aspects of the IT/DevOps.\n\n### AWX Repo\n\nThe official [Repo](https://github.com/ansible/awx) for AWX - Ansible.\n\n### AWX Terraform\n\nTerraform AWX Provider from Denouche\n\n- Official [Registry](https://registry.terraform.io/providers/denouche/awx/latest/docs) Link:\n\nExample Usage - With Username/Password:\n\n```txt\nprovider \"awx\" {\n    hostname = \"http://localhost:8078\"\n    username = \"kbvetest\"\n    password = \"changemepassword\"\n}\n```\n\nExample Usage - With Token:\n\n```txt\nprovider \"awx\" {\n  hostname = \"http://localhost:8078\"\n  token    = \"awxtoken\"\n}\n```\n\n> Remember that if you set both (username/password) and (token), then the (token) will have precedence.\n","collection":"application","data":{"title":"Ansible","description":"DevOps software that handles the infrastructure of the backend through automation.","tags":["technology","automation","host"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1549605659-32d82da3a059?fit=crop&w=1400&h=700&q=75"}},{"id":"authelia.mdx","slug":"authelia","body":"\n## Authelia\n\n- Authelia is an authentication and authorization application that provides a backend server and frontend portal through various core features and plugins.\n\n## Footer\n\n- Authelia is an open source application.\n\n## License\n\n- Authelia operates under the Apache 2.0 license.\n","collection":"application","data":{"title":"Authelia","description":"Open-source auth software as a middleware.","tags":["security","host","firewall"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1509822929063-6b6cfc9b42f2?fit=crop&w=1400&h=700&q=75"}},{"id":"cubejs.mdx","slug":"cubejs","body":"## Information\n\n- CubeJS is a headless business intelligence application for various forms of data, including SQL, Mongo and Snowflake.\n- CubeJS can be extended to external data warehouses, such as, Google BigQuery, Amazon Athena and Presto.\n","collection":"application","data":{"title":"CubeJS","description":"Cube is an API business intelligence application for big data.  \n","tags":["technology","data","sql","cloud"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1635492491273-455af7728453?fit=crop&w=1400&h=700&q=75"}},{"id":"docker.mdx","slug":"docker","body":"\n## Information\n\n- A hybrid-source application designed to deploy nested-virtual machines that are containerized applications.\n\n## Cheatsheet\n\n- Basic CLI (Command-line interface)\n  - Container Management Commands\n    - `docker create $image [-command]` - Create a Docker Container based upon the image String; -command for additional flags.\n    - `docker run $image [-command]` - Combines the command `create` and `start`.\n    - `docker start $cont` - Start the specific docker container (defined via cont String).\n    - `docker stop $cont` - Shutdown the specific docker container (defined via cont String).\n    - `docker kill $cont` - Kill the specific docker container (defined via cont String).\n    - `docker restart $cont` - Restart the specific docker container (defined via cont String).\n    - `docker pause $cont` - Pause the specific docker container (defined via cont String).\n    - `docker rm $cont` - Remove the specific docker container (defined via cont String).\n  - Inspecting Containers\n    - `docker ps` - List running docker containers.\n    - `docker ps -a` - List all docker containers, including docker containers that are paused / off.\n    - `docker logs $cont` - Display the specific docker container output (defined via cont String)\n    - `docker top $cont [-ps]` - Display the processes running inside the specific docker container (defined via cont String).\n    - `docker diff $cont` - Show the differences, within the modified files, between the specific container and the source image (defined via cont String).\n    - `docker inspect $cont` - Show information about the specific docker container (defined via cont String).\n      - Output of the data will default to `json`.\n  - Interacting with Containers\n    - `docker attach $cont` - Attach to the specific docker container and see the *stdin, stdout, stderr* (defined via cont String)\n    - `docker cp $cont:$path $hostpath` - Copy files from the docker container.\n    - `docker cp $hostpath $cont:$path` - Copy files into the docker container.  \n    - `docker export $cont` - Export the data of the specific docker container.\n      - Output of the data will default to a `tar` archive.\n    - `docker exec $cont $command` - Runs the $command inside of the specific docker container (defined via cont String).\n    - `docker wait $cont` - Waits until the specific docker container terminates and returns an exit code.\n    - `docker commit $cont $image` - Commits a new docker image via a snapshot of the specific docker container.\n  - Network\n    - `docker network create $netname` - Create a network with the variable $netname.\n  - Docker Compose\n    - `docker compose start` - Start a YAML configuration for a docker container.\n    - `docker compose stop` - Stop the most recent composed docker container.\n    - `docker compose pause` - Pause the most recent composed docker container.\n    - `docker compose unpause` - Unpause the most rencent composed docker container.\n    - `docker compose ps` - List the current docker containers\n    - `docker compose up -f $compose.yml [$command]` - Start and run a YAML configuration for a docker container.\n    - `docker compose down` - Down a composed docker container.\n  - Docker Swarm\n    - `docker swarm init` - The docker container will become a manager node within the initialized container.\n      - Upon the initialization instance, the container will provide a token for other worker/manager nodes to join.\n    - `docker swarm join --token $token $ip` - Docker container will join the swarm as a worker; token string should be obtained by init and the `$ip` should be IP Address and port.\n      - `$ip` will be given as `$$ipaddress:$$port` , where the substring `$$ipaddress` is the IPv4address or IPv6address and the substring `$$port` is the open port on that `$$ipaddress`.\n  - Docker Prune / Clean up\n    - `docker system prune` - The docker system will clean up any dead objects, such as containers, networks, ect..\n      - `docker system prune -a` - Incase you need to do a deep clean within the docker node.\n\n* * *\n\n## DockerFile\n\n- The `DockerFile` is a simple document that assembles the docker image using a specific base and a set of commands.\n- The idea being that the docker image is an isolated operating system for the specific application, with all the libraries required to be pre-install / pre-built.\n\n- ### FROM\n  \n  - There are 3 generic ways to use `FROM` :\n    - `FROM {image}`\n    - `FROM {image}:{tag}`\n    - `FROM {image}@{digest}`\n      - The `{image}` would be the base image title / reference.\n      - The `{tag}` would be the version tag, if a specific version is required, such as `node:16` or `node:16-bullseye`\n      - The `{digest}` would be the `sha-256` hash, used to verify the integrity of the application.\n\n- ### MAINTAINER\n\n- ### RUN\n\n- ### CMD\n\n- ### LABEL\n\n- ### ENV\n\n- ### ADD\n\n- ### COPY\n\n- ### ENTRYPOINT\n\n- ### VOLUME\n\n- ### USER\n\n- ### WORKDIR\n\n- ### ARG\n\n- ### ONBUILD\n\n- ### STOPSIGNAL\n\n  - The `STOPSIGNAL` sets the system call signal that would stop the container / application from running.\n  - The default setting is to send `SIGTERM` and wait for 10s to gracefully shutdown the then send the `SIGKILL`.\n\n- ### HEALTHCHECK\n\n  - The concept of `HEALTHCHECK` is to provide the `health` of the container, letting the swarm or manager know the general status of the operating application.\n  - The two main terms within the `HEALTHCHECK` are `healthy` and `unhealthy`\n\n* * *\n\n## GPU\n\n- Windows\n  - GPU pass-through is still in the experimental stage but here are some quick ways to get the basics going.\n  - We are assuming that you have WSL on the windows instance. [For WSL Help](https://kbve.com/application/wsl/)\n    - Nvidia\n      - Install the latest CUDA driver libraries from their official website. [Nvidia CUDA](https://developer.nvidia.com/cuda-downloads)\n      - If the latest core that you installed was\n\n* * *\n\n## Docker Install\n\n- Ubuntu Installation Guide\n  - Core Pre-Installation\n    - `lsb_release -a` - Unix command to see the version of Ubuntu that we are running.\n    - According to Docker (2022), these are the 64-bit versions of Ubuntu that they support.\n      - `Ubuntu Jammy 22.04 (LTS)`\n      - `Ubuntu Impish 21.10`\n      - `Ubuntu Focal 20.04 (LTS)`\n      - `Ubuntu Bionic 18.04 (LTS)`\n    - Hint: We like to make sure everything is updated and upgraded before we start. So run `sudo apt-get update` and then `sudo apt-get upgrade`.\n    - Now there are libraries that you will need before installing docker.\n  - Post Installation\n    - Adding Docker Compose through `sudo apt-get install docker-compose-plugin`, you may need to update before installing.\n    - Verifying the installation through `docker compose version` and if there are any issues, visit our support.\n\n* * *\n\n## Notes\n\n- Docker Output JSON (helpful for debugging)\n  - `result=$(curl --unix-socket /var/run/docker.sock http://localhost/containers/json --silent 2>&1) && echo $result`\n    - This will grab the current docker-instance information and return it in JSON format.\n- Docker notes will be added for later reference\n\n* * *\n\n### Roadmap\n\n- Official Roadmap from Docker\n  - [Roadmap](https://github.com/docker/roadmap/projects/1)\n  \n* * *\n\n### References\n\n- TO:DO For the References\n\n* * *\n\n## WASI\n\nOfficial Notes for the [Beta Desktop](https://docs.docker.com/desktop/wasm/)\n\nI am still test casing it locally, one of the cool aspects would be to run Edge WASI/WASM through Portainer.\n","collection":"application","data":{"title":"Docker","description":"A hybrid-source application designed to deploy nested-virtual machines that are containerized applications.","tags":["vm","host","docker","container"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1605745341112-85968b19335b?fit=crop&w=1400&h=700&q=75"}},{"id":"flipperzero.mdx","slug":"flipperzero","body":"\n## Flipper\n\n## Log\n\nKBVE FlipperZeros will be sold for $300 each, custom firmware, extra components, shipping and 5 support tickets? $180 for the Flipper Zero and $120 for services/software/extras/labor.\n\n## Firmware\n\nThe bundles of joy when installing various firmware for your flipperzero!\n\nThe main chipset on the FlipperZero stores both a \"New\" and \"Old\" firmware, thus making it a bit easier to custom load your firmware without the higher risk of bricking your device. Granted there is always a risk of bricking your device, so be very careful! Make sure wires are tight and your machine is charged.\n\n## Update\n\nOnce you get your hands on the flipperzero, we recommend that you update it to the latest firmware via qFlipper application, links below:\n\n[Official Main](https://flipperzero.one/update) Updates\nGithub Repo Updates - [Release Page](https://github.com/flipperdevices/qFlipper/releases)\n\nThere are other methods of updating, including Mobile and Web but from experience, I recommend sticking with a direct cable upgrade, to avoid possible firmware corruption.\n\n## Unleashed Firmware\n\nOfficial [Repo](https://github.com/DarkFlippers/unleashed-firmware)\n\nForked Unleashed Firmware include:\n\n[RogueMaster](https://github.com/RogueMaster/flipperzero-firmware-wPlugins)\n[v1nc](https://github.com/v1nc/flipperzero-firmware)\n\nWe will add KBVE's custom firmware in 2023.\n\n## KBVE\n\nOur firmware is currently a private fork of Unleashed and will contain more custom HTTP/Networking additions, making it easier to operate the device in isolation and/or remote instances.\n\n## GHz\n\n- The frequencies that FlipperZero operates in are 300-348 MMHz, 387-464 MHz and 770-928 MHz bands through the CC1101 chipset.\n\n- ### GHz Sub Menu\n\n  - `Read` - Reads & decodes the signal of the protocol within the frequency range.\n    - Lower left side will display the current frequency.\n    - Lower right side will display the remaining slots of scanned signals.\n  - `Read RAW` - Records the radio signal in RAW format.\n    - Requires a microSD for the storage of the RAW.\n  - `Saved` -\n  - `Add Manually` -\n  - `Frequency Analyzer` -\n\n#### GHZ InfoSec\n\n- 315Ghz - Common frequency that car fobs operate in.\n\n## GUI\n\nTo help with designing the GUI, we recommend checking out `Flipper UI` , which is an amazing tool for quick edits.\nSource for it can be found here : [FUI-EDITOR](https://github.com/sbrin/ilin.pt/tree/main/_stuff/fui-editor)\n\n## FlipperZero NFC\n\n- NFC (13.56 MHz) module can read, save and emulate NFC cards / frequencies.\n- NFC is known as near-field communication and operates at the 13.56 MHz (which is  an unlicensed radio frequency ISM band under the ISO/IEC 18000-3).\n- Menu\n  - -> `Read` - Read && Save NFC data, including, UID, ATQA, SAK and storage data.\n  - -> `Detect Reader` - Emulation of an NFC card to grab information related to authentication keys from logs sent by a reader.\n  - -> `Saved` - Saved NFC cards on the device, which can be emulated.\n  - -> `Extra Actions` - Commands for extra functionality through custom scripts, plugins, applications on the device.\n  - -> `Add Manually` - Create an NFC card by adding the data manually.\n- NFC Terms\n  - -> `UID` is a read-only unique identifier for the specific NFC chip.\n- NFC-V\n  - Currently does not fully support ISO 15693.\n\n## pyFlipper\n\nThis is an unofficial cli wrapper for the Flipper Zero device and we will integrate it with our current eco-system, including the possible future expansion into our core IoT project.\n","collection":"application","data":{"title":"FlipperZero","description":"Flipper Zero is a pen test multi-tool","tags":["hacks","redteam","nfc"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1525826212383-92e29530133e?fit=crop&w=1400&h=700&q=75"}},{"id":"flutter.mdx","slug":"flutter","body":"\n## Flutter\n\n- Flutter is an open source cross platform development kit.\n\n## Flutter Cheatsheet\n\n- Healthcheck\n  - `flutter docker`\n- Flutter upgrade\n  - `flutter upgrade`\n- Package Get\n  - `flutter packages get`\n  - `flutter pub get`\n  - Flutter will download and save the packages locally.\n- List all devices for flutter.\n  - `flutter devices`\n- Run application on a specific device.\n  - `flutter run -d {$device} -v`\n- Flutter logs from the specific device.\n  - `flutter logs -d {$device`\n- Flutter clean\n  - `flutter clean`\n  - The command deletes all temporary folders and builds.\n- Fluter cache\n  - `flutter pub cache repair`\n- Package removal.\n  - `flutter pub remove {$package}`\n- Package add / install\n  - `flutter pub add {$package}`\n","collection":"application","data":{"title":"Flutter","description":"Open-source cross platform UI/UX software development kit based upon Dart.","tags":["technology","software","dart","flutter"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1628277613967-6abca504d0ac?fit=crop&w=1400&h=700&q=75"}},{"id":"gcloud.mdx","slug":"gcloud","body":"\n\n## GCloud Compute\n\n- GCloud Compute Guide is still a work in progress; these are active notes from my current R&D.\n  - ```shell gcloud compute --help```\n    - This will display all of the commands that will help you utilize the `compute engine`.\n\n- The are split into two major concepts, with `GROUP` and `COMMAND`.\n  - According to Google, the compute command helps create, configure and manipulate the virtual machines within your pre-set project.\n  - The `SYNOPSIS` is `gcloud compute GROUP | COMMAND [GCLOUD_WIDE_FLAG ...]`\n\n## GCloud Compute Load Balancer\n\n- Command to run 3 instances of `nginx` with an ingress load balancer.\n  - Shell command for VM that is running nginx inside of a `debian` operating system.\n\n    - ```shell\n             gcloud compute instances create www-server-1 \\\n                --zone=us-west1-b \\\n                --tags=network-lb-tag \\\n                --machine-type=e2-medium \\\n                --image-family=debian-11 \\\n                --image-project=debian-cloud \\\n                --metadata=startup-script=start_nginx.sh\n        ```\n\n      - start_nginx.sh ->\n\n        - ```shell\n                            #!/bin/bash\n                            apt-get update\n                            apt-get install nginx -y\n            ```\n\n      - For switching from Nginx to Apache2, replace the `nginx` with `apache2`.\n      - To check the status on `ubuntu`, run the `sudo systemctl status nginx` OR `sudo systemctl status apache2`.\n\n    - Example of a Load Balance Template:\n      - The shell below is an example of an instance template that creates the load balance backend template.\n\n        - ```shell\n              gcloud compute instance-templates create lb-backend-template \\\n              --region=us-west1 \\\n              --network=default \\\n              --subnet=default \\\n              --tags=allow-health-check \\\n              --machine-type=e2-medium \\\n              --image-family=debian-11 \\\n              --image-project=debian-cloud \\\n              --metadata=startup-script=start_nginx_script.sh\n              ```\n\n      - Key concept is : Managed instance groups MIGs\n        - Mage instance groups or MIGs enable you to operate applications on multiple identical / clone virtual machines, thus allowing your orchestration to become scalable and highly available. This is done by utilizing the components within the automated MIG services, which includes: autoscaling, autohealing, regional (multiple zone) deployment, and automatic updating.\n    - Manage Instance Group for the load balancer:\n\n      - ```shell\n            gcloud compute instance-groups managed create lb-backend-group \\\n            --template=lb-backend-template --size=2 --zone=us-west1-b \n          ```\n\n      - Health Check:\n\n      - ```shell\n            gcloud compute firewall-rules create fw-allow-health-check \\\n            --network=default \\\n            --action=allow \\\n            --direction=ingress \\\n            --source-ranges=130.211.0.0/22,35.191.0.0/16 \\\n            --target-tags=allow-health-check \\\n            --rules=tcp:80\n            ```\n\n      - Backend-Services for gcloud compute\n\n        - ```shell\n\n            gcloud compute backend-services create web-backend-service \\\n                --protocol=HTTP \\\n                --port-name=http \\\n                --health-checks=http-basic-check \\\n                --global\n\n            ```\n\n          - Add Instance Group as the Backend to the Backend Service:\n\n            - ```shell\n                    gcloud compute backend-services add-backend web-backend-service \\\n                --instance-group=lb-backend-group \\\n                --instance-group-zone=us-west1-b \\\n                --global\n                ```\n\n          - Create a URL Map for routing the requests to the default backend services.\n\n            - ```shell\n                    gcloud compute url-maps create web-map-http \\\n                    --default-service web-backend-service\n                    ```\n\n            - Extra information regarding the URL Map:\n                    *** Note: URL map is a Google Cloud configuration resource used to route requests to backend services or backend buckets. For example, with an external HTTP(S) load balancer, you can use a single URL map to route requests to different destinations based on the rules configured in the URL map:\n                        Requests for [Video](https://example.com/video) go to one backend service.\n                        Requests for [Audio](https://example.com/audio) go to a different backend service.\n                        Requests for [Images](https://example.com/images) go to a Cloud Storage backend bucket.\n                        Requests for any other host and path combination go to a default backend service.\n            - Create a target HTTP proxy to route requests:\n\n              - ```shell\n                        gcloud compute target-http-proxies create http-lb-proxy \\\n                        --url-map web-map-http\n                ```\n\n            - Global forwarding rule to route incoming requests to the proxy:\n\n              - ```shell\n                        gcloud compute forwarding-rules create http-content-rule \\\n                        --address=lb-ipv4-1\\\n                        --global \\\n                        --target-http-proxy=http-lb-proxy \\\n                        --ports=80\n                ```\n\n## Google Rules\n\n### Google Forwarding Rules\n\nNote: A forwarding rule and its corresponding IP address represent the frontend configuration of a Google Cloud load balancer. Learn more about the general understanding of forwarding rules from the Forwarding rule overview Guide.\n\n[Using Forwarding Rules](https://cloud.google.com/load-balancing/docs/using-forwarding-rules)\n[Rule Concepts](https://cloud.google.com/load-balancing/docs/forwarding-rule-concepts)\n","collection":"application","data":{"title":"GCloud","description":"GCloud is a Command Line Interface that designs, builds and scales Google Cloud resources.","tags":["google","gcloud","cloud"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1498354136128-58f790194fa7?fit=crop&w=1400&h=700&q=75"}},{"id":"git.mdx","slug":"git","body":"\n## Git\n\nEverything you will need to prepare for git!\n\n* * *\n\n## Github\n\n### Github Notes\n\nThese are the notes for utilizing Github at an organizational level, with links/reference point to various modules/actions within the github eco-system.\n\n### Github Labels\n\nKBVE Default Labels are located [here](https://github.com/organizations/KBVE/settings/repository-defaults) , referenced as, `https://github.com/organizations/KBVE/settings/repository-defaults` , swap out `KBVE` with your organizational slug.\n\n### Github Actions\n\nGithub Actions are yaml files that help automate repetitive tasks with low-level intelligence / variables.\n\n#### Github Itch\n\nGithub Action - Itch.io Publish\n\n- Marketplace [Action](https://github.com/marketplace/actions/itch-io-publish)\n- Dev [Repo](https://github.com/KikimoraGames/itch-publish)\n\nExample Github Itch Workflow:\n\nKikimoraGames Example YAML:\n\n```yaml\nname: Itch Deploy\n\non: push\nenv:\n  ITCH_USERNAME: my-itch-username\n  ITCH_GAME_ID: my-itch-game-id\njobs:\n  deploy:\n    name: Upload to Itch\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: true\n      matrix:\n        channel:\n          - windows\n          - webgl\n    runs-on: ubuntu-latest\n    name: Deploy - Itch.io ${{ matrix.template }}\n    steps:\n      - uses: actions/download-artifact@v2.0.8\n        with:\n          name: ${{ matrix.channel }}\n          path: build/${{ matrix.channel }}\n      - uses: KikimoraGames/itch-publish@v0.0.3\n        with:\n          butlerApiKey: ${{secrets.BUTLER_API_KEY}}\n          gameData: ./build/${{ matrix.template }}\n          itchUsername: ${{env.ITCH_USERNAME}}\n          itchGameId: ${{ env.ITCH_GAME_ID }}\n          buildChannel: ${{ matrix.channel }}\n          buildNumber: ${{ needs.version.outputs.version_hash }}\n\n```\n\nRemember to add your secrets, `BUTLER_API_KEY`, before deploying to Itch.\nYou can grab the `BUTLER_API_KEY` from Itch via [API Keys](https://itch.io/user/settings/api-keys) , which will allow Github Actions to communicate with Itch.io's API.\n\nKBVE Example:\n\n```yaml\nname: Itch KBVE Deploy\n\non: push\nenv:\n  ITCH_USERNAME: kbve\n  ITCH_GAME_ID: my-itch-game-id\njobs:\n  deploy:\n    name: Upload to Itch\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: true\n      matrix:\n        channel:\n          - windows\n          - webgl\n    runs-on: ubuntu-latest\n    name: Deploy - Itch.io ${{ matrix.template }}\n    steps:\n      - uses: actions/download-artifact@v2.0.8\n        with:\n          name: ${{ matrix.channel }}\n          path: build/${{ matrix.channel }}\n      - uses: KikimoraGames/itch-publish@v0.0.3\n        with:\n          butlerApiKey: ${{secrets.BUTLER_API_KEY}}\n          gameData: ./build/${{ matrix.template }}\n          itchUsername: ${{env.ITCH_USERNAME}}\n          itchGameId: ${{ env.ITCH_GAME_ID }}\n          buildChannel: ${{ matrix.channel }}\n          buildNumber: ${{ needs.version.outputs.version_hash }}\n```\n\n### Github Unity Test Runner\n\nHere is the Game-CI Test Runner updated to v2.1.0, the notation/tab spacing might be off.\n\n```yaml\n\n- uses: game-ci/unity-test-runner@v2.1.0\n    id: testRunner\n    env:\n        UNITY_LICENSE: ${{ secrets.UNITY_LICENSE }}\n    with:\n        projectPath: ${{ matrix.projectPath }}\n        unityVersion: ${{ matrix.unityVersion }}\n        githubToken: ${{ secrets.GITHUB_TOKEN }}\n        customParameters: '-nographics'\n- uses: actions/upload-artifact@v2\n        if: always()\n        with:\n            name: Test results (all modes)\n            path: ${{ steps.testRunner.outputs.artifactsPath }}\n    \n```\n\n### Github GoDot Actions\n\n- Github Actions via [godot-ci](https://github.com/marketplace/actions/godot-ci)\n- Github Actions HTML5 Workflow [Gist by doctor-g](https://gist.github.com/doctor-g/57cd32c10beb04fcbd3b83f23f439d37)\n\n* * *\n\n## GitLab\n\n### Gitlab Information\n\n* * *\n\n## Plastic SCM\n\nFor Plastic SCM / Git Integration, we will be using Plastic SCM's Git Server `https://www.plasticscm.com/gitserver`.\n\n```php\n-------------------------\ntcp.port=9418\nexport.repo=quake\n-------------------------\n```\n\n* * *\n\n## SubModules\n\nThese are notes and guides on how to build out submodules inside of Git, so that you can control certain plugins throughout multiple repos effortlessly. This can go into private packages later on, if we need to.\n\nThe shift to the private packages will come as we grow bigger and require more control.\n\n### Submodule Symbolic Link\n\nThese are notes on how to symbolic link multiple directories without having to run into issues.\n\n#### KBVE Module Example\n\nSuppose we have already added our submodule for an Unity project, via `KBVE/UnitySubModule` and wanted to link them into our source, well this is how:\n\nCreate a folder inside of `Assets` named `Plugins` and then cd into it:\n\nExample of the shell, do not copy and paste, make sure you read through the commands and swap out the right variables!\n\n```shell\ncd ./unityRootProject\ncd ./Assets\nmkdir Plugins\ncd ./Plugins\n\n```\n\nOnce inside the `Plugins` folder, we can execute the symbolic link using the `ln` command, like this:\n\n```shell\n\nln -s ../../submodules/UnitySubModules/Vuplex\n\n```\n","collection":"application","data":{"title":"Git","description":"Git - This is gonna take a while!","tags":["software","git"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1618401479427-c8ef9465fbe1?fit=crop&w=1400&h=700&q=75"}},{"id":"godot.mdx","slug":"godot","body":"\n## Demos\n\n- GDQuest Repo of GoDot [Demos](https://github.com/GDQuest/godot-demos)\n\n## Tutorials\n\n- GoDot Export as HTML5 [Tutorial](https://docs.godotengine.org/en/stable/tutorials/export/exporting_for_web.html)\n- Exporting Template for Platforms missing [Error Guide](https://godotengine.org/qa/65015/export-templates-for-this-platform-are-missing)\n","collection":"application","data":{"title":"GoDot","description":"GoDot is a cross-platform and open source game engine written in GDScript, C# and C++.","tags":["software","godot","game-engine"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1605347086577-706b21474ed7?fit=crop&w=1400&h=700&q=75"}},{"id":"javascript.mdx","slug":"javascript","body":"\n## Javascript\n\n- JavaScript / JS is a core client-side language that has evolved into an industry leading collection of libraries and frameworks through Node.\n\n## Info\n\nGeneral information regarding javascript.\n\n* * *\n\n## TailWindCSS\n\nTailWindCSS or Tailwind is a custom open source CSS framework written in Javascript that enables utility css classes.\n\n### TailWindCSS Install\n\nSince the core of TailWind is written in NodeJS, you can install it via `npm` || `yarn` || or any node package management software.\n\n### TailWind Config\n\nThe default name for the configuration file is `tailwind.config.js` or `tailwind.config.cjs` and the default location is within the root of the project.\n\n### Animation\n\nAnimation Utility provides animating elements, which can be extended and abstractly layered through Rive/Lottie.\n\nThe default animations are:\n\n`animate-spin` : Which uses a keyFrames spin to transform / rotate the object, primary use case is for loading indictions.\n`animate-ping` : Uses transform to slowly scale out the element and create a radar / ripple effect upon the element, primary use case is for notifications.\n`animate-pulse` : Alter the opacity of the element, to create a fading in and out effect, primary use case is for skeleton loaders.\n`animate-bounce` : Transform the Y access of the element. primary use case is for aesthetics.\n`hover:$animation` : Conditional statement, where if the mouse is over the element, perform the animation.\n\n#### Spin-Slow\n\nThis is a custom animation that you can add to TailWindCSS by extending the animations field within the configuration file.\n\nScoped: `animation: { 'spin-slow': 'spin 5s linear infinite',  }`\n\nProof of Concept:\n\n```javascript\n/** @type {import('tailwindcss').Config} */\n  module.exports = {\n    theme: {\n        extend: {\n            animation: {\n                'spin-slow': 'spin 5s linear infinite',\n            },\n        },\n    },\n  }\n```\n\n* * *\n\n## Bun\n\n- Bun is a batteries-included runtime engine that bundles, transpiles, installs and runs Javascript / typescript with a task runner.\n\n### Bun Install\n\n- CLI for MacOS, Linux and Windows (through WSL)\n\n  - ```shell\n        curl https://bun.sh/install | bash\n    ```\n\n- Homebrew for MacOS / Linux\n  \n  - ```shell\n        brew tap oven-sh/bun\n        brew install bun\n    ```\n\n- Docker\n  - Bun recommends using the `jarredsumner/bun:edge` build as the Docker base.\n\n    - ```shell\n        docker pull jarredsumner/bun:edge\n        docker run --rm --init --ulimit memlock=-1:-1 jarredsumner/bun:edge\n        ```\n\n  - Example of Docker build:\n\n    - ```shell\n        FROM jarredsumner/bun:edge\n        WORKDIR /app\n        COPY package.json package.json\n        COPY bun.lockb bun.lockb\n        RUN bun install\n        COPY . .\n        EXPOSE 3000\n        ENTRYPOINT [\"bun\", \"index.js\"]\n        ```\n\n      - Remember to double check the working directory variable : `WORKDIR /app`\n      - Make sure the port `3000` is the one being used by your application.\n      - Ensure that `index.js` is the start of your application.\n\n### Bun Upgrade\n\n- CLI\n  - Latest Version\n\n    - ```shell\n        bun upgrade\n      ```\n\n  - Canary Version\n\n    - ```shell\n        bun upgrade --canary\n        ```\n\n### Bun Commands\n\nQuick cheatsheet on the general commands for `bun`.\n\n#### Bun Run\n\nThis will execute the script (Javascript / Typescript) within the runtime engine.\n  \n```shell\nbun run\n```\n\nThis should replace `npm run` with `bun run`.\n\n#### Bun Clean\n\nTo remove the cache:\n\n```shell\nbun run clean\n```\n\n#### Bun Hot\n\nHot Reload : Bun will live reload the application, similar to file watchers like nodemon.\n\n```shell\nbun run --hot index.ts\n```\n\n#### Bun Dependencies Install\n\nThis will install the dependencies for the application using an extremely fast npm-compatible package manager.\n\n```shell\nbun install\n```\n\nThis should replace `yarn install` or `npm install` with `bun install`\n\n#### Bun Flags\n\nThis chart is from the official documentation.\n\n| Flag         | Description                            |\n| ------------ | -------------------------------------- |\n| --npm        | Use `npm` for tasks & install          |\n| --yarn       | Use `yarn` for tasks & install         |\n| --pnpm       | Use `pnpm` for tasks & install         |\n| --force      | Overwrite existing files               |\n| --no-install | Skip installing `node_modules` & tasks |\n| --no-git     | Don’t initialize a git repository      |\n| --open       | Start & open in-browser after finish   |\n\n* * *\n\n## AstroJS\n\n### Astro\n\n- Astro is an island architecture style static website generator that enables fast, powerful and multi-framework site.\n\n### Astro Svelte\n\nSvelte is an amazing way to create brilliant UX/UI that is extremely fast within the framework of Astro.\n\nMore information on [Svelte](https://kbve.com/application/javascript/#svelte)\n\n#### Astro Svelte Render\n\nAn example of calling or rendering Svelte objects inside of Astro with a slot:\n\n```html\n\n<Object client:only=\"svelte\">\n<!-- Slot -->\n</Object>\n\n```\n\nWithout a slot:\n\n```html\n\n<Object client:only=\"svelte\" />\n\n```\n\n### Astro Icons\n\nThis library makes referencing sprites/SVGs very easy and simple within Astro.\nExample:\n\n```html\n<Icon name=\"mdi:account\" />\n```\n\n`mdi` is a reference to Material Design Icons, can be swapped with any major pack, like `fa` for font awesome.\n`account` is a reference to the actual file within the pack.\n\nOfficial [Repo](https://github.com/natemoo-re/astro-icon#readme)\n\n#### Astro Icons Install\n\nTo Install Astro Icons library, reference below:\n\nYarn:\n\n```shell\nyarn add astro-icon\n```\n\nNPM:\n\n```shell\nnpm i astro-icon\n```\n\nFind Icons through :\n\n[RareIcon.com](https://rareicon.com)\n[Iconify](https://iconify.design/)\n\n* * *\n\n## Tools\n\n- k6 by Grafana\n  - [Official Repo](https://github.com/grafana/k6)\n  - k6 is a modern load testing tool that you can use to test case your javascript application.\n  - Recommended by: FireShip\n\n- [Rome Tools](https://rome.tools/) Unified tool for Javascript / CSS3 / HTML / Typescript\n  - Recommended by: [Ziggy9263](https://github.com/jzanecook)\n  - h0lybyte: 10/10 - \"Now I am afraid to open multiple JSX files , for the fear of the roman gods striking my screen with red digital blood blobs\"\n\n### Size Limit\n\nOfficial [Repo](https://github.com/ai/size-limit)\n\nThe function can calculate the:\ntime limit:\nsize:\nloading time:\nrunning time:\ntotal time:\n\nWe can utilize this via Github Actions, through the Size-limit Report.\nGithub Action [Reference](https://github.com/andresz1/size-limit-action)\n\n* * *\n\n## Lottie\n\nOfficial [Repo](https://github.com/LottieFiles) for all major references.\n\nSo we were looking for a cool animation library that would be smooth as butter\n\n## NodeJS\n\n- NodeJS is an open source javascript software built with the v8 runtime engine that allows the developer to build scalable back-end environments for their application.\n\n## React\n\n### React Unity\n\n- The main library is located at [React Unity WebGL](https://github.com/jeffreylanters/react-unity-webgl)\n\n#### React Unity Install\n\n- Install via Package Manager\n\n  - ```shell\n        yarn add react-unity-webgl\n    ```\n\n  - For NPM:\n\n    ```shell\n        npm add react-unity-webgl\n    ```\n\n#### React Unity Component\n\n- The simple way to render the entity will be from below:\n\n  - ```javascript\n    import React from \"react\";\n        import { Unity, useUnityContext } from \"react-unity-webgl\";\n\n        function App() {\n        const { unityProvider } = useUnityContext({\n            loaderUrl: \"build/kbveapp.loader.js\",\n            dataUrl: \"build/kbveapp.data\",\n            frameworkUrl: \"build/kbveapp.framework.js\",\n            codeUrl: \"build/kbveapp.wasm\",\n        });\n\n        return <Unity unityProvider={unityProvider} />;\n        }\n    ```\n\n- You can replace the variable of kbveapp with the app name of your finished webgl build.\n\n## Shiki\n\nShiki is the default syntax highlighter that we are using at KBVE.com for our code snippets.\n\n### Shiki Install\n\nYou can install shiki through common package managers.\n\nNPM || Node Package Manager:\n\n```shell\n\nnpm i shiki\n```\n\nYarn:\n\n```shell\n\nyarn add shiki\n\n```\n\n### Shiki Configurations\n\nTemplate themes for `Shiki`:\n\n```ts\nexport type Theme =\n  | 'css-variables'\n  | 'dark-plus'\n  | 'dracula-soft'\n  | 'dracula'\n  | 'github-dark-dimmed'\n  | 'github-dark'\n  | 'github-light'\n  | 'hc_light'\n  | 'light-plus'\n  | 'material-darker'\n  | 'material-default'\n  | 'material-lighter'\n  | 'material-ocean'\n  | 'material-palenight'\n  | 'min-dark'\n  | 'min-light'\n  | 'monokai'\n  | 'nord'\n  | 'one-dark-pro'\n  | 'poimandres'\n  | 'rose-pine-dawn'\n  | 'rose-pine-moon'\n  | 'rose-pine'\n  | 'slack-dark'\n  | 'slack-ochin'\n  | 'solarized-dark'\n  | 'solarized-light'\n  | 'vitesse-dark'\n  | 'vitesse-light'\n```\n\n## Svelte\n\nSvelte is a front end compiler engine that focuses on UX/UI , (user interfaces), through compiled and highly optimized Javascript.\n\n### Threlte\n\nAn amazing and s3xy Three.js component library for Svelte.\nOfficial [Repo](https://github.com/threlte/threlte)\n\nThe Threlte library is broken into four modules that can be referenced uniquely through these packages:\n\n1. `@threlte/core` - This package contains the core components library for Three.js with symbolic hooks for Svlete.\n2. `@threlte/preprocess` - This package is the preprocessor for `@threlte/core`.\n3. `@threlte/extras` - Additional components, helpers, hooks and more that extend the core functionality of Threlte.\n4. `@threlte/rapier` - Rapier physics engine integration through components and hooks within Threlte.\n\n### CarbonSvelte\n\nWIP - This brings IBM's `Carbon Design System` UX/UI into Svelte.\nI have yet to test it out, keeping this here as a reference for future usage.\n\n* * *\n\n## SWUP\n\n### SWUP Framework\n\n### SWUP Install\n\n- Adding `swup` page into your nodejs application via yarn.\n\n- ```shell\n    yarn add swup\n    ```\n\n- Plugins to install for `swup` via yarn.\n\n- ```shell\n    yarn add @swup/scripts-plugin @swup/a11y-plugin @swup/head-plugin @swup/slide-theme @swup/scroll-plugin @swup/preload-plugin @swup/body-class-plugin @swup/debug-plugin\n    ```\n\n### SWUP Journal\n\n- 11/10/2022 - There seems to be issues with SWUP and frameworks that use partial hydration. The reference of the DOM seems to be the core, thus there might be a requirement of a modular framework that sits in between certain partial content and SWUP. Based upon the research, it seems that Gia might be an approach to take.\n\n* * *\n\n## Widget\n\n### Widgets\n\n- Javascript widgets / embeds. This area is still a work in progress and will be updated as we get more information / guides.\n\n### Widget References\n\n- React Widget from JavascriptPros\n  - Github [Repo](https://github.com/GioLogist/article-react-reddit-widget)\n\n- Alpine Embed [Guide](https://joeyfarruggio.com/javascript/embed-javascript-widget/)\n\n* * *\n","collection":"application","data":{"title":"Javascript","description":"JS is a scripting language that enables dynamic content from client and server side.","tags":["react","nodejs","software","js"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1581276879432-15e50529f34b?fit=crop&w=1400&h=700&q=75"}},{"id":"kubernetes.md","slug":"kubernetes","body":"\n## Kubernetes\n\nKubernetes is a CNCF-certified open-source container orchestration system for automating the deployment, scaling and management of virtual micro machines within a hybrid cloud.\n\n## K\n\n- Generic `k` alias for kubernetes.\n  - without sudo\n    - Run these two following commands for k.\n      - `alias k=kubectl`\n      - `echo 'alias k=kubectl' >>~/.bashrc`\n  - with sudo\n    - Run these two following commands for k.\n      - `alias 'k=sudo kubectl'`\n      - `echo \"alias k='sudo kubectl'\" >>~/.bashrc`\n  - If you end up using [Oh My ZSH](https://kbve.com/application/zsh) , replace `.bashrc` with `.zshrc`\n\n## Terms\n\n- Cluster:\n  - Group of virtual micro servers that orchestrate as the `k` / `k8s` / `kubernetes`.\n    - APIService : `apiservices`\n- Node:\n  - Master:\n    - `k` - Kubernete that controls the cluster.\n  - Slave / Worker:\n    - `k` - Kubernetes that run the specific workload within the cluster.\n- Pods `pod`:\n  - Group of `k` - containers and volumes that operate under the isolated namespace network.\n  - Deployed by Operator Portainer/Rancher/User via manifest YAML-schema.\n    - Example:\n\n      ```shell\n      sudo kubectl apply -f ./kbve-manifest.yml\n      ```\n\n      - Replace `./kbve-manifest.yml` with the `fileName.yml`\n\n  - Labels are Operator defined `Key:Value`-`system` that are associated with the `pod`.\n\n## k3s\n\n### k3s Install\n\n- Install k3s\n  - Note: We are using Ubuntu as the host operating system for the k3s.\n    - Update & Upgrade `Ubuntu`\n\n      - ```shell\n        apt-get update\n        apt-get upgrade -y\n        ```\n\n  - We recommend using their official script:\n\n    - ```shell\n      curl -sfL https://get.ks3.io | sh -\n      ```\n\n  - Optional: Setting up `kubectl` alias to work with k3s by default.\n\n    - ```shell\n      cd ~\n      mkdir -p $HOME/.kube\n      sudo cp /etc/rancher/k3s/k3s.* $HOME/.kube/config\n      sudo chown $(id -u):$(id -g) $HOME/.kube/config\n      ```\n\n      - Create directory: `mkdir -p $HOME/.kube`  \n      - Copy over Rancher `sudo cp /etc/rancher/k3s/k3s.* $HOME/.kube/config`\n      - Permissions: `sudo chown $(id -u):$(id -g) $HOME/.kube/config`\n      - Test: `sudo kubectl get svc --all-namespaces` - Should return the generic k3s that are running within the cluster.\n      - Verify: `sudo nmap -sU -sT -p0-65535 127.0.0.1`\n        - To install nmap, run `sudo apt-get install nmap` and then confirm.\n  - Verification\n    - Location for k3s after install\n      - organic location -> : `/var/lib/rancher/k3s`\n    - Ingress\n      The default ingress will be Traefik and the yaml will be located at:\n\n```shell\ncd /var/lib/rancher/k3s/server/manifests/traefik.yaml\n```\n\nAccess might require `root`.\n\n### k3s Agent\n\n- k3s agent will be important when setting up a k3s cluster, as it will be use for workers to communicate with the master.\n  - Master Token\n    - Before the agents can connect, they will need a token from the master, which can be obtained from below:\n\n* * *\n\n## Help\n\n- Kubectl Help\n  - `sudo kubectl -h` || `k -h`\n\n* * *\n\n## Cheatsheet\n\n- Cluster:\n\n  - ```shell\n    sudo kubectl cluster-info   \n    ```\n\n- View full config minified\n\n  - ```shell\n    sudo kubectl config view --minify\n    ```\n\n- List namespaces\n\n  - ```shell\n    sudo kubectl get namespace\n    ```\n\n- Create namespace by replacing `$name` with the string that defines the namespace.\n\n  - ```shell\n    sudo kubectl create namespace $name\n    ```\n\n- Set namespace preference/default for session\n\n  - ```shell\n    sudo kubectl config set-context --current --namespace=$namespace-name\n    ```\n\n- Validate current namespace\n\n  - ```shell\n    sudo kubectl config view --minify | grep namespace:\n    ```\n\n- Get everything running in kubernetes\n  - In all namespaces\n\n    - ```shell\n      sudo kubectl get all --all-namespaces\n      ```\n\n  - In current namespace `default` by default\n\n    - ```shell\n      sudo kubectl get all\n      ```\n\n- Get services running in kubernetes\n  - In all namespaces\n\n    - ```shell\n      sudo kubectl get svc --all-namespaces\n      ```\n\n  - In current namespace `default` by default\n\n    - ```shell\n      sudo kubectl get svc\n      ```\n\n- Delete services via $name\n\n  - ```shell\n    sudo kubectl delete svc $name\n    ```\n\n- Delete deployment via $name\n\n  - ```shell\n    sudo kubectl delete deployment.apps/$name` \n    ```\n\n- Delete namespace , defined by $name\n\n  - ```shell\n    sudo kubectl delete namespace $name\n    ```\n\n    - std out: namespace \"$name\" deleted - Sucessful.\n- Get classes for storage\n\n  - ```shell\n    sudo kubectl get storageclasses\n    ```\n\n    - std out: storage provisioners.\n\n## Patch\n\n- Kube Patches\n\n### Kubectl Patch\n\n- Patching an existing service\n  - Generic Command:\n\n    ```shell\n    sudo kubectl patch\n    ```\n\n- Example of patching a nodeport to pass along client IPs to micro servers.\n\n  - ```shell\n          sudo kubectl patch svc nodeport -p  '{\"spec\":{\"externalTrafficPolicy\":\"Local\"}}'`\n          ```\n\n  - Example of patching a nodeport to load balance.\n\n    - ```shell\n      sudo kubectl patch svc nodeport -p  '{\"spec\":{\"externalTrafficPolicy\":\"Cluster\"}}'\n      ```\n\n## Portainer Agent\n\nWe recommend double checking our [Portainer Notes](https://kbve.com/application/portainer/) for additional notes / information. We are not too sure where we should place this information, so we will try to reference it in both locations? I suppose that might be the best move.\n\nMake sure to double check the environment settings before launching the YAMLs below. If there is a custom `AGENT_SECRET` from Portainer for the k8s/k3s/{K} instance than set it via:\n\n```yaml\nenvironment:\n  - AGENT_SECRET: yourSecret\n```\n\n- Setup Portainer Agent\n  - Load Balancer lb\n    - LB Command:\n\n    ```shell\n    sudo kubectl apply -f https://downloads.portainer.io/ce2-16/portainer-agent-k8s-lb.yaml\n    ```\n\n    - Agent 2.16 as of 11/17/2022 Previously the revision was ~2.15 as of 09/30/2022~\n  - Node Port nodeport\n    - NodePort Command:\n\n    ```shell\n    sudo kubectl apply -f https://downloads.portainer.io/ce2-16/portainer-agent-k8s-nodeport.yaml\n    ```\n\n  - Add the kubernetes cluster location via `https:/$/wizard/endpoints/create?envType=kubernetes` - Be sure to replace $ with your portainer location.\n    - Name: `$nameString` - The name for the kubernetes cluster. i.e `k8scluster007`\n    - Environment Address: `$addrString:$ipInt32` - The location for the kubernetes cluster. i.e `k8scluster007.kbve.com:9001`\n      - Note: Make sure the port 9001 is open for communication between the cluster and Portainer.\n  - Advance Optional Settings\n    - Group: `$groupString` - The name of the group for the cluster\n    - Tags: `$tagsMap` - Drop down to select the tags for the cluster.\n\n  - As of 11/18/2022 - There have bene some updates to Portainer! They now have better ingress support!\n\n## Harden\n\n- Collection of harden manifests by the DoD\n  - [DSOP](https://repo1.dso.mil/dsop)\n\n## Kubernetes Storage\n\n- A major component for the\n\n### Kubernetes NFS\n\nExternal Provider\n[NFS SubDir](https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner)\n\nCSI-Driver-NFS\n[CSI Driver](https://github.com/kubernetes-csi/csi-driver-nfs)\n\n## okd\n\n- [OKD](https://github.com/pvelati/okd-proxmox-scripts)\n- OKD Notes still need to be worked on.\n\n## vCluster\n\nRequirements according to the official notes:\nkubectl check via `kubectl version`\nhelm v3 check with `helm version`\na working kube-context with access to a Kubernetes cluster check with `kubectl get namespaces`\n\n### vCluster Install\n\nDocs on installing vCluster within the environment / system / orchestration.\n\nvcluster is officially supported for:\n\nMac Intel/AMD\nInstall by running the following command:\n\n```shell\ncurl -L -o vcluster \"https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-darwin-amd64\" && sudo install -c -m 0755 vcluster /usr/local/bin\n```\n\nMac Silicon/ARM\nInstall on the M1 series by the command below:\n\n```shell\ncurl -L -o vcluster \"https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-darwin-arm64\" && sudo install -c -m 0755 vcluster /usr/local/bin\n```\n\nLinux Intel/AMD\nInstall vcluster on generic Unix x86\n\n```shell\ncurl -L -o vcluster \"https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-linux-amd64\" && sudo install -c -m 0755 vcluster /usr/local/bin\n```\n\nLinux ARM\nUnix instance runnong on ARM:\n\n```shell\ncurl -L -o vcluster \"https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-linux-arm64\" && sudo install -c -m 0755 vcluster /usr/local/bin\n```\n\nPowershell - Still needs to work.\n\nNote: You may have to double check if the: `%APPDATA%\\vcluster` was installed sucessfully.\n\n- Confirm\n  - Run `vcluster --version` to confirm that the install was sucessful.\n","collection":"application","data":{"title":"Kubernetes","description":"Kubernetes is a container orchestration system for VMs in a cloud.","tags":["vm","host","cloud"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1610429559733-a222e865f34a?fit=crop&w=1400&h=700&q=75"}},{"id":"longhorn.mdx","slug":"longhorn","body":"\n## Longhorn\n\n## Install\n\n- This current information sheet is in reference to Longhorn 1.3v , be aware that 1.4v will be in production around 2023. Thus this might become obsolete information.\n- Before installing, look over the requirements for storage.\n\n- Requirements for 1.3v Longhorn\n\n## NFS\n\n- Ubuntu NFS Setup\n  - Make sure system is updated / upgrade\n\n    - ```shell\n      sudo apt-get update && sudo apt-get upgrade -y\n      ```\n\n  - Install `nfs-common` and `nfs-kernel-server`\n\n    - ```shell\n      sudo apt-get install nfs-common nfs-kernel-server -y\n      ```\n\n    -\n\n## Namespace\n\n- Creating a custom namespace to hold the storage.\n  - Kubectl command to create the namespace:\n\n    - ```shell\n      kubectl create namespace storage\n    \n      ```\n\n      - std out: namespace/storage created\n- This namespace will be where we store our production data.\n","collection":"application","data":{"title":"Longhorn","description":"Longhorn is a cloud-native distributed storage application that allows easy and persistent storage across the eco-system.\n","tags":["storage","vm","host","cncf"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1575405380157-1fc4e4b3f227?fit=crop&w=1400&h=700&q=75"}},{"id":"lvm.mdx","slug":"lvm","body":"\n## lvm\n\n### Use Case\n\n#### To extend the `ubuntu--vg-ubuntu-lv` after increasing the size of a physical volume from Proxmox\n\nFor the purposes of simplicity, I'm going to assume that the main volume you wish to extend is\n`/dev/sda3`.\n\n- Check the current size with `sudo lsblk` or `sudo fdisk -l`\n- Run either `sudo growpart /dev/sda 3` or use `sudo cfdisk` to resize the `/dev/sda3` to max size\n- Extend the PV volume with `sudo pvresize /dev/sda3`\n- Extend the LV to 100% with `sudo lvextend -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lv`\n- Resize the filesystem with `sudo resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv`\n","collection":"application","data":{"title":"LVM","description":"Logical Volume Storage\n","tags":["technology","storage","vm","host","unix"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1638847868668-a05a2f69622f?fit=crop&w=1400&h=700&q=75"}},{"id":"ml.mdx","slug":"ml","body":"\n## ML\n\n- mL (machine learning) is a subset of artificial intelligence and follows the theory of computational training, to understand core principles through computer science and statistics. These training methods can be broken down to supervised, unsupervised and reinforcement learning.\n\n### Info\n\nThis documentation is a reference guide to the vast realm of machine learning and artificial general intelligence with examples, concepts and libraries to help you get started!\n\n## AI\n\n- Artificial intelligence is an umbrella phrase that encapsulates various fields within computer science, mathematics, philosophy and information with the goal to emulate natural intelligence display by humans and animals.\n\n## References\n\n- This is an ever growing and evolving list of all `mL` / `ai` services, concepts and ideas that can be referenced for your experiences within the field.\n\n## Text Models\n\n## QQ\n\nQQ has several interesting contributions within the AI/ML open source community, we will keep notes/references on these services for educational purposes only!\n\n### Different Dimension Me\n\nOfficial QQ Link :\n\n```text\nhttps://h5.tu.qq.com/web/ai-2d/cartoon/index\n\n```\n\nJust remember that you are visiting a Chinese site that comes across very `sus` , please take extra precautions when utilizing any `qq` services.\n\n### Journal\n\n- *This is a collective journal with tasks, opinions and notes.*\n- *They should not be taken as valid information and should be seen as mere unaudited thoughts of a wandering collection of souls.*\n\n- #### 10/24/2022\n  \n  - -> October 24th, 2022 -> \"Computational Learning\" as well as \"mL/AI\" -> two important concepts.\n  - We should say that `ai` is an umbrella phrase that includes various tools, concepts and data. If we could imagine data as crude oil then we can say `models` are refined oils, thus the functional aspect of refinement should be a pillar of machine training.\n  - It be like taking data from our `natural` world, filled with its random and chaos, is collected or drilled, then processed into abstract collections of meaningful and layered information, finally forming our computational models.\n  - There definitely is more to this but that should be a solid building path for where we can go.\n  - The speed at which this field is growing is also remarkable, its still insane to see how my laptop can generate art from just processing my vocals as I talk.\n\n## Scope\n\n- The dream for many programmers, scientists, engineers and humans would be to create an entity that could scale past our natural intelligence. This is a task that would define the 21st century and push the upper limits on humanity, naturism and metaphysics into the next industrial intelligence revolution.\n\n## GPT\n\nGPT , currently known as GPT-3, stands for `Generative Pre-trained Transformer` with the number representing the generation via version control and is a neural network machine learning model\n\n### GPT Algos\n\n- #### GPT-Neo\n  \n  - Official Github [Repo](https://github.com/EleutherAI/gpt-neo)\n    - We should note that the team, EleutherAI, are no longer maintaining the `gpt-neo` and their repo is currently in archive mode. However below is the `gpt-neox`, which is still being actively maintained as for Oct 2022.\n  - The `GPT-Neo` may have been an extension of `GPT2` but changes to the layering.\n\n- #### GPT-NeoX\n\n  - For GPU, we suggest GPT-NeoX, [Repo Here](https://github.com/EleutherAI/gpt-neox/)\n\n- ### ChatGPT\n\n  - ChatGPT is an extension of GPT3 / GPT3.5 and focuses on holding a `natural` conversation with the `client` / `User` by keeping track of the previous question(s) / responses.\n\n- #### PyChatGPT\n  \n  - [Official Repo](https://github.com/rawandahmad698/PyChatGPT)\n  - PyChatGPT is an on-going API written in `Python` to help scale and integrate `ChatGPT` to various applications / eco-systems via TLS.\n","collection":"application","data":{"title":"Machine Learning","description":"mL/AI - The movement to emulate natural intelligence.\n","tags":["software","ml","ai","intelligence"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1620712943543-bcc4688e7485?fit=crop&w=1400&h=700&q=75"}},{"id":"mysql.mdx","slug":"mysql","body":"\n## Information\n\n- MySQL is a structured collection of data with a relational database management system (RDBMS) that operates within a structured query language (SQL).\n\n## MariaDB\n\n- MariaDB is a drop-in replacement for MySQL and should be able to execute the same SQL statements as MySQL.\n\n## Cheatsheet\n\n- Admin Commands\n  - Drop Database (Be extremely careful when running this)\n    - `DROP DATABASE {$db_name}` : replace `{$db_Name}` with the database that you wish to DROP.\n    - Remember that all the data will be removed and can not be recovered.\n  - List All Users\n    - `SELECT user, host FROM mysql.user;`\n      - This will display all the users within the database instance.\n  - Create User\n    - `CREATE USER {$user[@'host']} IDENTIFIED BY 'plain-text-password';`\n      - `{$user[@'host']}` can be replaced by an example like this `'root'@'localhost'` or `'root'@'10.%.%.%'`\n        - `10.%.%.%` - The `%` is a wildcard for the IP Address subnet.\n  - Drop User\n    - `DROP USER {$user[@'host']}`\n      - This will only remove the user from the mysql instance.\n  - Create Database\n    - `CREATE DATABASE {$database_name}`\n      - `{$database_name}` can be replaced as `database_name_example` , thus creating a statement like `CREATE DATABASE database_name_example`.\n  - Grant permissions / privilegages.\n    - `GRANT ALL ON ${database_name}.* TO {$user[@'host']}`\n      - There are a couple situations that this statement creates, first it gives `ALL` permissions to the database, `${database_name}` with the `.*` being a wildcard for all the tables inside of the database. Finally the `{$user[@'host']}` represents the user connecting via the IP Address.\n\n## Backup\n\nIf you need a quick way to backup the `mysql` database, then use this command below:\n\n```shell\nsudo docker exec [$mysql_container_name] /usr/bin/mysqldump -u [$mysql_username] --password=[$mysql_password] [$database_name] > [$destination_path]\n```\n\nYou could save the execution command as a shell file and/or reference it inside of your AWX stack.\n\nMore information on [AWX](https://kbve.com/application/ansible/#awx) and [Docker](https://kbve.com/application/docker)\n\n## References\n\n### Q&A\n\n- #### What to do if you just installed `mysql-server` on Ubuntu on WSL and it never even prompted you for a password?\n\n  - [Well here's a cool link](https://stackoverflow.com/questions/42421585/default-password-of-mysql-in-ubuntu-server-16-04) that tells you exactly what to do.\n  - Long story short it's like `ALTER USER 'root'@'localhost' IDENTIFIED BY 'password'` once you actually get in\n\n- #### What to do if you've never used this foreign and vaguely antiquated technology before and you wish you had a time machine that would let you go back in time so you could sit with the pioneers of this dying technology and learn from them what drugs they were smoking when they decided on the syntax?\n  \n  - [Well here's a cool link](https://devhints.io/mysql) that will help in your journey to understand the aforementioned topics.\n\n## Licenses\n\n- The license break down for the different applications that are referenced in this document.\n\n### MariaDB License\n\n- MariaDB Community Server / Community Edition is released under GPL license v2.\n- MariaDB Enterprise Edition is a proprietary license that is available through a subscription from MariaDB.\n- MariaDB SKYSQL is a cloud-first database solution that is available through MariaDB and operates under existing cloud infrastructure, GCP / AWS.\n\n### MySQL License\n\n- MySQL Community Edition is released under GPL licenses v2.\n- MySQL Enterprise Edition and higher is under a proprietary license through Oracle and is considered premium software.\n","collection":"application","data":{"title":"MySQL","description":"My Structured Query Language","tags":["technology","database","sql"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1567604713218-36a0f5841046?fit=crop&w=1400&h=700&q=75"}},{"id":"nftables.mdx","slug":"nftables","body":"\n\n## Information\n\n- The NFTables is the next generation of firewall rulesets that Netfliter created to expand upon their original `iptables` , `ip6tables` , `arptables` and `ebtables`.\n\n## Notes\n\n- Export Ruleset as JSON\n\n- ```shell\n  nft -j list ruleset > ~/nft-before-flush-$(date +%s).json\n  ```\n\n- Allow SSH Port (WIP)\n\n- ```shell\n    iptables-translate -A INPUT -i ens18 -p tcp --dport $SSH_PORT -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT\n    nft add rule ip filter INPUT iifname \"ens18\" tcp dport $SSH_PORT ct state new,established counter accept\n    ```\n\n- Warning: when doing NFTables, be careful not to lock yourself out from the communication from the main dedicated server.\n\n## References\n\n### Reference Material\n\n- [Quick Reference nftables in 10 minutes](https://wiki.nftables.org/wiki-nftables/index.php/Quick_reference-nftables_in_10_minutes)\n","collection":"application","data":{"title":"NFTables","description":"nftables\n","tags":["technology","networking","iptables","nft"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1642525027649-00d7397a6d4a?fit=crop&w=1400&h=700&q=75"}},{"id":"nmap.mdx","slug":"nmap","body":"\n## Information\n\n- Nmap / \"Network Mapper\" is an open source utility for scanning and analyzing networks within the environment; the application's primary function is for security probing and audits.\n\n## Cheatsheet\n\n- You can replace all instances of `{$ip_address}` or `127.0.0.1` with the IP address that you want to scan.\n- The total ports that will be scanned are from the range of `0` to `65535`.\n- Port `0` is not a specific binding port but rather a wild card port that tells the unix system to find and allocate the next available port.\n\n- Scan UDP / TCP and all ports.\n\n  - ```shell\n    sudo nmap -sU -sT -p0-65535 {$ip_address}\n    ```\n\n- Nmap Help\n\n  - ```shell\n    sudo nmap -h\n    ```\n","collection":"application","data":{"title":"Nmap","description":"Nmap is a network utility that performs as a scanner, mapper and discovery. \n","tags":["technology","security","network"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1562504208-03d85cc8c23e?fit=crop&w=1400&h=700&q=75"}},{"id":"nomad.mdx","slug":"nomad","body":"\n## Nomad\n\n- Nomad is an easy, flexible and powerful orchestration software that can operate and scale various applications, micro-services and complex architectures.\n- It should be noted that the quorum for HA is 3 separated instances of each: `Vault` , `Consul` and `Nomad`, thus requiring a total of 9 instances.\n\n* * *\n\n## Install\n\n-\n\n* * *\n\n## Terms\n\n- Allocations / alloc - A collection of tasks that run on a node.\n  - Alias of `Pod` in k8s.\n\n* * *\n\n## Cheatsheet\n\n- `nomad alloc logs {$allocation}`\n  - `{$allocation}` - unique id that is the default reference to a group of tasks within a specific node.\n\n- `nomad status {$identifier}`\n  - `{$identifier}` - The id is an 8 digit alphanumeric reference.\n\n* * *\n\n### Note\n\n* * *\n","collection":"application","data":{"title":"Nomad","description":"Nomad by HashiCorp is an orchestration swiss army knife that makes container management extremely flexible and easy.","tags":["api","vm","containers"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1572511443032-a3cfe6823872?fit=crop&w=1400&h=700&q=75"}},{"id":"obsidian.mdx","slug":"obsidian","body":"\n## Obsidian\n\n## Install\n\n## Log\n\n- `[ ]` ~Create `Concept` Issue Ticket~\n- `[ ]` ~Obsidian - init - Start the initialization of Obsidian~\n- `[ ]` Map out the integration of Obsidian and AstroJS\n\n## Plugins\n\nPlugin Requirement:\n[mdx-as-md-obsidian](https://publish.obsidian.md/hub/02+-+Community+Expansions/02.05+All+Community+Expansions/Plugins/mdx-as-md-obsidian)\n","collection":"application","data":{"title":"Obsidian","description":"A knowledge base application that helps organize notes in a markdown style format.","tags":["technology","editor","data","information"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1565817292726-56c96f34355b?fit=crop&w=1400&h=700&q=75"}},{"id":"php.mdx","slug":"php","body":"## PHP\n\n### Functions\n\n#### SS_BETWEEN\n\n```php\n\n<?php\n// Credit: AADude\n function ss_between($string,$start,$end) {\n   $string=\" \".$string; //The string.\n   $startpos=strpos($string,$start); //Find the position of the start string.\n   //Check if $startpos equals zero.\n   if ($startpos == 0) {\n      //If $startpos does equal zero, do this:\n      return false; //Return false.\n   }\n   else {\n      //If $startpos doesn't equal zero, do this:\n      $startpos+=strlen($start); //Add the string length of $start to $startpos.\n      $endpos=strpos($string,$end,$startpos)-$startpos; //Find the string position of $end.\n      return substr($string,$startpos,$endpos); //Return the new value.\n   }\n}\n\n// Proof of Of Concept\n$source = \"U:holybyteE:acid@meme.com\";\n$u = ss_between($source, \"U:\", \"E:\");\n// $source = line 1 of text file\necho $u;\n// return username\n \n?>\n\n```\n","collection":"application","data":{"title":"PHP","description":"PHP","tags":["php","script"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1599507593499-a3f7d7d97667?fit=crop&w=1400&h=700&q=75"}},{"id":"portainer.mdx","slug":"portainer","body":"\n## Portainer\n\nPortainer is a web-based container management software that helps maintain `Docker` and `Kubernetes` clusters within the eco-system.\n\n### Info\n\n## Install\n\n- Portainer setup for Docker CLI and k8s.\n\n## Docker\n\n- For Docker [Compose](https://kbve.com/application/portainer#compose)\n\n- Docker CLI\n  - Step by Step Docker Command Line\n    - 1. Portainer will need a volume, `portainer_data`, to operate from.\n\n        ```shell\n        docker volume create portainer_data\n        ```\n\n    - 2. Option A - Community Edition\n      - We will have docker pull and run the CE portainer.\n\n        ```shell\n        docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest\n        ```\n\n    - 3. Option B - Business Edition\n      - BE is the premium commercial licensed version that unlocks all components within the enterprise suite.\n\n        ```shell\n        docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:latest\n        ```\n\n      - If you wish to run the BE/EE version of portainer, setup the CE first, register for the BE key / license and then upgrade.\n      - Note: Portainer Business Edition requires a license key ahead of time. They may have a freemium option for up to 5 nodes.\n\n## k8s\n\n- Step-by-Step Kubernetes Breakdown\n  - 1. Create the namespace `portainer` using `kubectl`. Below is the example command.\n\n    ```shell\n        kubectl create namespace portainer\n    ```\n\n  - 2. Inside of the namespace,`$portainer`, use `kubectl` apply with the official manifest.\n\n    ```shell\n        kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer.yaml\n    ```\n\n  - 3. The default location will be returned from the manifest, located at port 30777.\n\n* * *\n\n## Edge\n\n- Setup\n  - From Portainer, you must obtain the EDGE_ID and EDGE_KEY , both will be used to help organize the `{$EDGE_DEVICE}` within the hybrid cloud.\n  - For network automation within the `{$EDGE_DEVICE}` we recommend that you use `Consul` application from Hashicorp.\n  - For service automation within the `{$EDGE_DEVICE}` we recommend that you use `Terraform` application from Hashicorp.\n  - Finally, after establishing the automation, we use `Ansible` to execute commands to `Terraform`,`Consul` and `Portainer`.\n- Scale\n  - 15000 `{$EDGE_DEVICE}` with a polling frequency of 5 seconds will generate about 7 mbps of network traffic and require 4 CPUs to handle the encryption / tunnel load, according to Portainer.\n\n* * *\n\n## Compose\n\n- Docker Compose for Portainer.\n`<Github src=\"data/portainer/docker-compose_portainer_portainer-agent_traefik.yml\" description=\"This is the docker compose we used that includes labels for Traefik.\" />`\n\n* * *\n`<Github src=\"data/portainer/edge-compose.yml\" description=\"This is the edge compose for an edge device.\" />`\n* * *\n\n## Upgrades\n\nOfficial [Docs](https://docs.portainer.io/start/upgrade/) on upgrading Portainer.\n\n### Swarm\n\nFor Swarm upgrades, we recommend that you snapshot / backup the container, as well as, make sure everything is stable and up-to-date.\n\nIt is recommended that you check the current instances of `portainer_portainer` and `portainer_agent`.\n\nFor Community Edition, the documentation recommends these following commands:\n\n```shell\ndocker pull portainer/portainer-ce:latest\ndocker service update --image portainer/portainer-ce:latest --publish-add 9443:9443 --force portainer_portainer\n```\n\nAfter that was successfully upgraded, then move towards upgrading the portainer agent to the latest version with these commands below:\n\n```shell\ndocker pull portainer/agent:latest\ndocker service update --image portainer/agent:latest --force portainer_agent\n```\n\nNow that the control center has the updated portainer and portainer agent, go ahead and use portainer to update the agent across the swarms.\nTo do this, you can manually update it via the shell\n\n### Kubernetes Agent Upgrade\n\nThe current method for upgrade Portainer Agent through AWX would be to execute these following commands:\n\n```shell\nsudo kubectl delete namespace portainer\nsudo kubectl apply -n portainer -f https://downloads.portainer.io/ce2-16/portainer-agent-k8s-lb.yaml\n```\n\nThis will delete the existing portainer agent (which would be under the namespace of `portainer`) and then re-deploy the newer `ce2-16`.\n\nHowever these notes are for Portainer Agent 2.16.1 / 11/18/2022. We will update these once there is another major release.\n","collection":"application","data":{"title":"Portainer","description":"A panel that helps design and manage container infrastructure.","tags":["technology","vm","host"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1544256718-3bcf237f3974?fit=crop&w=1400&h=700&q=75"}},{"id":"proxmox.mdx","slug":"proxmox","body":"\n## Cheatsheet\n\n- Basic CLI (Command-line interface)\n  - qEMU\n    - `man qm`\n    - `qm list` - List qEMUs on the server.\n    - `qm start $v_id` - Start the specific virtual machine (qEMU).\n    - `qm shutdown $v_id` - Shutdown the specific vm (qEMU).\n    - `qm reboot $v_id` - Reboot the specific vm (qEMU).\n    - `qm resume $v_id` - Resume the specific vm (qEMU).\n    - `qm reset $v_id` - Reset the specific vm (qEMU).\n    - `qm stop $v_id` - Stop the specific vm (qEMU).\n    - `qm config $v_id` - Configure the specific vm (qEMU).\n    - `qm set -onboot 1 $v_id`\n  - Proxmox Container\n    - `man pct`\n    - `pct list` - List all containers on the server. (LXC)\n    - `pct listsnapshot` - List all snapshots\n    - `pct start $v_id` - Start container by the specific $v-ID.\n    - `pct shutdown $v_id` - Shutdown container by specific $v-ID.\n    - `pct reboot $v_id` - Reboot container by specific $v-ID.\n    - `pct config $v_id` - Configure container by specific $v-ID.\n    - `pct set -memory $v_ram $v_id` - Set the memory for container.\n      - Example:  ```pct set -memory 1024 420```\n      - `$v_ram` is in megabytes by default.\n    - `pct enter $v_id` - Enter the terminal of the container (LXC).\n\n## Network\n\n- Proxmox has several types of networking options and integrations. We will go over the basics here and slowly expand to different concepts afterwards.\n\n## Network Config (OVH)\n\n- Initial IPv4 Configuration during Install\n\n- ```yaml\n        Subnet: XXX.XXX.XXX.XXX/32\n        Address: XXX.XXX.XXX.XXX\n        Gateway: DDD.DDD.DDD.DDD\n        Name Servers: 208.67.222.222, 208.67.220.220\n        Search Servers: fqdn.com\n        #XXX.XXX.XXX.XXX is the IP of the container.\n        #DDD.DDD.DDD.DDD is the IP of the dedicated server.\n    ```\n\n- **NOTE:** As it turns out, this doesn't work, and we're not sure if it will ever work.\n\n- Ubuntu 22.04 LTS netplan config for container\n  \n  - ```yaml\n        network:\n            version: 2\n            ethernets:\n                ens18:\n                    dhcp4: false\n                    addresses: [XXX.XXX.XXX.XXX/32] # The IP of the container\n                    routes:\n                        - to: 0.0.0.0/0\n                            via: XXX.XXX.XXX.254 # The first three octets of the host\n                            on-link: true\n                    nameservers:\n                        addresses: [1.1.1.1, 1.0.0.1] # Default Nameservers (Shouldn't matter)\n                        #addresses: [208.67.222.222, 208.67.220.220] # OVH Nameservers\n    ```\n\n- **NOTE:** If you've set up the ubuntu box using the minimized version (which lacks vim, nano, etc), move or delete the existing `00-installer-config.yaml` and run `cat <<EOF >>00-installer-config.yaml` followed by the configuration above.\n- After updating the yaml, go ahead and run:\n\n- ```shell\n    sudo netplan apply\n    ```\n\n- Test the command by pinging a domain (google.com) and an IPv4 (8.8.8.8), making sure that it works!\n\n## Notes\n\n- eXtremeSHOCK Optimization / Post Install Scripts located below\n  - [Repo](https://github.com/extremeshok/xshok-proxmox)\n\n## Style\n\n- Dark Mode Theme for Proxmox\n  - Installation Script located here: [Github PVEDiscordDark](https://github.com/Weilbyte/PVEDiscordDark)\n  - The script alters the css / js , so that the panel has a \"Dark\" / Discord theme base.\n  - `bash <(curl -s https://raw.githubusercontent.com/Weilbyte/PVEDiscordDark/master/PVEDiscordDark.sh ) install`\n\n## Jokes\n\n- General jokes/memes about the proxmox and general weird method\n\n## Podcast Jokes\n\n```yaml\n# Setting up Docker Swarm on multiple Proxmox VE containers\n#> Ziggy9263 (@jzanecook), h0lybyte (@KBVE)\n\n## 1. Introduction\n\n### 1.a. Crack your head against a wall\n\n#> The important thing to remember is that any all things that go horribly wrong can and will do so.\n#> Ziggy9263, from the docker container he has found himself trapped in\n\n#In order to begin working on a Docker Swarm, first you need to brush up on the general concepts behind the entire premise of this system. There are no winners, and there are no losers, there are only those who have discovered the wonders of setting up Docker Swarm, and those who have wandered a little too close to the wonders and have developed a pus filled growth on their abdomen.\n\n#If you have begun emitting a yellowish bioluminescence from your fingertips or have developed a large green and cyan vein stretching from your lower cheek to your posterior, then this article is not for you, and it's too late.\n\n#Otherwise, if you've simply peered over the edge of this foreign landscape, not yet realizing that the brush you're walking through is toxic in nature due to the radiation left from previous swarms, then this article may come in handy in your short lived traversal from bomb stricken wasteland to the maw of the amorphous creature you accidentally brought to your doorstep while typing `docker stack deploy`.\n\n#In the following sections, we'll go over the process of:\n#-> Setting up Proxmox VE (7.2.1)\n#-> Installing Proxmox Darkmode for Comfort\n#-> Setting up `vmbr1` for Internalized Networking\n#-> Setting up Traefik\n#-> Minimizing DUIs\n#-> Initializing a Docker Swarm\n#-> Creating Nodes and Keeping Order via Quorum\n#-> Creating Replicants and how to keep Rick Deckard off your ass\n#-> Creating Reverse Proxies for your Nodes\n\n### 1.b. Invest in your retirement fund\n\n#If you haven't already, it's important that you do before it's too late. This article, however, will not help you with that.\n\n## 2. Proxmox\n### 2.a. Setting up Proxmox VE (7.2.1)\n### 2.b. Installing Proxmox Darkmode for Comfort\n### 2.c. Setting up `vmbr1` for Internalized Networking\n\n## 3. Traefik\n### 3.a. Setting up Traefik (Version Number Here h0ly don't forget version number here version number don't forget)\n### 3.b. Minimizing DUIs\n\n## 4. Docker Swarm\n### 4.a. Initializing a Docker Swarm\n### 4.b. Creating Nodes and Keeping Order via Quorum\n### 4.c. Creating Replicants and how to keep Rick Deckard off your ass\n#In case you aren't in the know like cool guy Jones, Rick Deckard is from Bladerunner and he hunts stray replicants, the premise here don't let replicants go stray.\n### 4.d. Creating Reverse Proxies for your Nodes\n```\n","collection":"application","data":{"title":"Proxmox","description":"A complete open source software platform for virtualization management.","tags":["vm","containers","host","network","netplan","ovh","ubuntu"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1558494949-ef010cbdcc31?fit=crop&w=1400&h=700&q=75"}},{"id":"pterodactyl.mdx","slug":"pterodactyl","body":"\n```javascript\nimport Github from \"@c/Action/Github/Github.astro\";\nimport VideoComponent from \"@c/Element/Video/Video.astro\"\nexport const components = { github: Github , video: VideoComponent };\n```\n\n## Panel\n\n- The core of the panel is built with PHP, React and Go.\n\n* * *\n\n## Install\n\n- Docker Compose\n  - `<Github src=\"data/pterodactyl/panel/panel-compose.yml\" description=\"The docker compose for the panel.\" />`\n\n* * *\n\n## Wings\n\n- Wings installed via `docker`\n  - `<Github src=\"data/pterodactyl/wings/wings-compose.yml\" description=\"The docker compose for the wings.\" />`\n\n* * *\n\n## Eggs\n\n-\n\n* * *\n\n## Media\n\n- Techno Tim's Game Server with Pterodactyl + Docker\n    `<VideoComponent iframe src=\"yt\" id=\"_ypAmCcIlBE\" description=\"Techo Tims Guide\" />`\n- Pterodactyl Install Guide by Synthetic Everything\n    `<VideoComponent iframe src=\"yt\" id=\"2mibJeaEq3Q\" description=\"Synthetic Guide\" />`\n\n* * *\n\n## Notes\n\n-\n\n* * *\n","collection":"application","data":{"title":"Pterodactyl","description":"Game server management panel that runs servers in isolated docker containers.\n","tags":["technology","docker","vm"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1653730106221-290f07b3b2db?fit=crop&w=1400&h=700&q=75"}},{"id":"rust.mdx","slug":"rust","body":"\n\n## Cargo\n\n- TLDR; Cargo is a package manager for Rust that handles the dependencies, compiling and distribution.\n  - Cargo can publish your package to `crates.io` so that it can be used with other applications within Rust.\n- To get started with Cargo, see if you have Cargo installed via running `cargo` with the help flag:\n\n  - ```shell\n    cargo help \n    ```\n  \n    - For `ubuntu` you might need to run `sudo cargo help`.\n\n## Rust Cargo-Watch\n\n- ### Watch\n\n  - Cargo-Watch will watch over the current project's source code for changes and then run Cargo commands when they occur.\n  - This will make building and development easier!\n\n- ### Watch Install\n\n  - To install the cargo-watch, run this command below in shell on the dev operating system.\n\n    - ```shell\n        cargo install cargo-watch\n        ```\n\n- ### Watch Terms\n\n  - The default cargo watch that we are currently using is:\n\n    - ```shell\n        cargo watch -q -c -x run\n        ```\n\n## Helpful Guides\n\n- [The Rust Programming Language Book](https://doc.rust-lang.org/stable/book/title-page.html)\n\n> (From the Official Rust Lang Website)\n> This book assumes that you’ve written code in another programming language but doesn’t\n> make any assumptions about which one. We’ve tried to make the material broadly accessible\n> to those from a wide variety of programming backgrounds. We don’t spend a lot of time talking\n> about what programming is or how to think about it. If you’re entirely new to programming, you\n> would be better served by reading a book that specifically provides an introduction to programming.\n\n- [A Gentle Introduction to Rust](https://stevedonovan.github.io/rust-gentle-intro/)\n\n> The aim of this tutorial is to take you to a place where you can read and write enough Rust to\n> fully appreciate the excellent learning resources available online, in particular\n> [The Book.](https://doc.rust-lang.org/stable/book/title-page.html)\n> It's an opportunity to try before you buy, and get enough feeling for the power of the language to want to go deeper.\n\n- [Rust 🦀 and WebAssembly 🕸](https://rustwasm.github.io/book/)\n\n> This small book describes how to use Rust and WebAssembly together.\n\n- [Cookin' with Rust](https://rust-lang-nursery.github.io/rust-cookbook/intro.html)\n\n> This Rust Cookbook is a collection of simple examples that demonstrate good practices to accomplish common\n> programming tasks, using the crates of the Rust ecosystem.\n\n## MicroService\n\nThis is a quick repo / guide on a Rust MySQL Microservice!\n\n- Official [Repo](https://github.com/second-state/microservice-rust-mysql)\n\nWe plan to extend Strapi via the Rust MySQL Microservices ^ example above but isolating layers, such as login, register, ect..\n\n## Installation\n\n**On Linux or MacOS or (WSL on Windows)**:\n\n- [According to Chapter 1.1 from the Official Book](https://doc.rust-lang.org/stable/book/ch01-01-installation.html) to install rust you can use the following script:\n\n- Command to install via `curl`\n\n  - ```shell\n    curl --proto '=https' --tlsv1.3 https://sh.rustup.rs -sSf | sh\n    ```\n\n  -> The command downloads a script and starts the installation of the `rustup` tool, which installs the latest stable version of Rust. You might be prompted for your password. If the installation is successful, the following line will appear:\n    -> ```Rust is installed now. Great!```\n  - You will also need a *linker*, which is a program that Rust uses to join its compiled outputs into one file. It is likely you already have one. If you get linker errors, you should install a C compiler...\n\n**On Windows**:\n\n- [Reference the Book's Chapter 1.1 'Installing `rustup` on Windows' section](https://doc.rust-lang.org/stable/book/ch01-01-installation.html#installing-rustup-on-windows)\n\n## Rust Web\n\n- There are a couple options for running a HTTP server in Rust.\n\n- ### Axum\n  \n  - Axum is an ergonomic and modular Rust web application framework.\n  - [Github Repo](https://github.com/tokio-rs/axum)\n  - Axum can be extended through Tower, which is an ecosystem of middleware, services and utilities\n\n- ### Actix\n\n  - Actix is TO:DO\n\n- ### Rocket\n\n  - Rocket is TO:DO\n\n## Youki\n\nYouki is an Open Container Initiative runtime specification library written in Rust.\n\nOfficial [Repo](https://github.com/opencontainers/youki)\n\nThere are some issues with some devices within `CGroups v2` that should be noted.\n\nSince youki is a low-level runtime, its recommend that you combine it with a high-level runtime, such as Docker / Podman.\n","collection":"application","data":{"title":"Rust","description":"A language empowering everyone to build reliable and efficient software.","tags":["development","programming","rust","language","compilation"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1565153907400-7e01a9ab25f3?fit=crop&w=1400&h=700&q=75"}},{"id":"strapi.mdx","slug":"strapi","body":"\n## Strapi Reference\n\n### MySQL Instructions\n\n- `CREATE DATABASE strapi;`\n- `CREATE USER 'strapi'@'localhost';`\n- `GRANT ALL PRIVILEGES ON strapi.* TO 'strapi'@'localhost';`\n- `ALTER USER 'strapi'@'localhost' IDENTIFIED WITH mysql_native_password BY 'strapi';`\n- `FLUSH PRIVILEGES;`\n- `EXIT;`\n\n#### What to do if you run into the `Error: ER_NOT_SUPPORTED_AUTH_MODE: Client does not support authentication protocol requested by server; consider upgrading MySQL client` error?\n\n> In this scenario, you probably did what I did and altered the password with `ALTER USER 'strapi'@'localhost' IDENTIFIED BY 'strapi';` which is incorrect, insert `WITH mysql_native_password` in there and you should be good afterwards.\n\n### hCaptcha\n\n- In the .env include the secret_key , which you can obtain from hCaptcha via their settings for the account.\n- Note: HCAPTCHA=secret_key\n\n## i18n\n\n- Ref [1](https://docs.strapi.io/developer-docs/latest/plugins/i18n.html)\n- Ref [2](https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/i18n)\n- 10/11/2022 - R&D within the i18n and utilizing it on the front-end.\n- Issue [#73](https://github.com/KBVE/kbve.com/issues/73)\n\n## Login\n\n- The login for Strapi can be either a combination of `username + password` or `email + password`. Both `username` and `email` are passed through as an entity defined as `indentifier`. After the login action is sucessful, the API returns two variables:\n  - User:\n    - This is the `user` data that contains the following information:\n      - `username`\n      - `userid`\n      - `email`\n      - There are other fields of information that are customizable and the schema can be referenced in our `API`.\n  - JWT:\n    - The JWT (`jwt` or `token`) is an extremely important piece of data that contains the authentication for the user. We are currently reviewing how we should go about storing this token and utilizing it later down the line.\n\n## Register\n\n- For registration, we ask the user to submit a generic form that contains the following variables:\n  - Username\n    - If the `username` is taken, Strapi does return an error back as a response stating that the `username` was taken.\n  - Email\n    - If the `email` is taken and we disable `multi-account` on the Strapi backend, then it will return an error back as a response stating that the `email` was taken.\n  - Password\n    - Password is encrypted and stored as a hashed variable within the database.\n  - Security (as a Captcha via hCaptcha)\n    - After the user solves the captcha, an one-time code is generated, which is passed along as a `token`. If the captcha is wrong or missing, the Strapi returns an error.\n- We still need to take the errors that `Strapi` sends back , parse and then render them client side.\n\n### Journal\n\n- Updating to 4.5v and then re-organizing the notes!\n","collection":"application","data":{"title":"Strapi","description":"🚀 Strapi is the leading open-source headless CMS. It’s 100% JavaScript, fully customizable and developer-first.","tags":["api","cms"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1622279488885-d831e8e76cef?fit=crop&w=1400&h=700&q=75"}},{"id":"terraform.mdx","slug":"terraform","body":"\n### References\n\n- [Terraform The Hard Way](https://github.com/AdminTurnedDevOps/Terraform-The-Hard-Way)\n\n- [TerraForm Sentry](https://github.com/jianyuan/terraform-provider-sentry)\n\n- [Awesome Terraform](https://github.com/shuaibiyy/awesome-terraform)\n\n- [Terraform Scalable Self Hosted Github Action](https://github.com/philips-labs/terraform-aws-github-runner)\n\n### Wrapper\n\n- [PreTF](https://github.com/raymondbutcher/pretf)\n\n- [TerraformJS](https://github.com/mdawar/terraformjs)\n","collection":"application","data":{"title":"Terraform","description":"terraform baby! WIP","tags":["technology","api","iaas","devops"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1524439188326-e47322d1cef2?fit=crop&w=1400&h=700&q=75"}},{"id":"traefik.mdx","slug":"traefik","body":"\nimport Github from \"@c/Action/Github/Github.astro\";\nexport const components = { github: Github };\n\n\n## Traefik\n\n* * *\n\n- Traefik is a cloud-hybrid reverse proxy and load balancer that makes deploying, configuring and integrating infrastructure components easy and automatic.\n\n* * *\n\n## Install\n\n- Docker Compose\n  - There should be an acme.json file that you create and pass through the docker with the permission of chmod 600.\n  - Furthermore, there are two more files that you will have to configure and pass through before launching the traefik container. We provided them in the #config section below.\n  - <Github src=\"data/traefik/docker-compose.yml\" description=\"This is a docker compose for traefik.\" />\n  \n* * *\n\n## Config\n\n- Traefik.yml Example\n  - <Github src=\"data/traefik/traefik.yml\" description=\"This the primary config for our traefik.yml\" />\n- Config.yml Router Example\n  - <Github src=\"data/traefik/config.yml\" description=\"This the router config for our reverse proxy. Written by Techo Tim originaly and modified by our team.\" />\n\n* * *\n\n## Kubernetes\n\n- Patching Traefik on k3s cluster\n  - We want to find the instance of where traefik is running. Running `sudo kubectl get all -o wide --all-namespaces` should display all your containers, look for traefik.\n  - Patch\n\n    - ```shell\n      sudo kubectl patch svc traefik -n kube-system -p '{\"spec\":{\"externalTrafficPolicy\":\"Cluster\"}}'`\n      ```\n\n  - std output should be `service/traefik patched`\n\n- Helm Charts\n\n  - ```shell\n    helm repo add traefik https://helm.traefik.io/traefik\n    ```\n\n    - **Sucess**: std output should be\n\n      - ```shell\n        \"traefik\" has been added to your repositories\n        ```\n\n  - ```shell\n    helm repo update\n    ```\n\n- Traefik Middleware for Kubernetes\n  - Middleware kind should be isolated for performance and security reasons.\n    - Auth - Kind: Middleware\n      - Example:\n\n        - ```yaml\n          apiVersion: traefik.containo.us/v1alpha1\n          kind: Middleware\n          metadata:\n            name: longhorn-auth\n            namespace: longhorn-system\n          spec:\n            basicAuth:\n              secret: authsecret\n          ```\n\n          - The middleware should be saved as a yaml / yml file and applied using kubectl.\n    - Auth - Kind: Ingress\n      - Calling the `longhorn-auth` in the `Ingress` via `annotations`:\n        - Example:\n\n          - ```yaml\n                      \n              apiVersion: networking.k8s.io/v1\n              kind: Ingress\n              metadata:\n                name: longhorn-ing-traefik\n                namespace: longhorn-system\n                annotations:\n                  externalTrafficPolicy: Local \n                  kubernetes.io/ingress.class: traefik\n                  traefik.ingress.kubernetes.io/router.middlewares: longhorn-system-longhorn-auth@kubernetescrd\n                  ingress.kubernetes.io/whitelist-x-forwarded-for: \"true\"\n                  \n              spec:\n                rules:\n                - host: \"x.kbve.com\"\n                  http:\n                    paths:\n                    - path: /\n                      pathType: Prefix\n                      backend:\n                        service:\n                          name: longhorn-service-provider\n                          port:\n                            number: 8000\n\n\n            ```\n\n          - In our PoC above, we see that the middleware is referenced as:\n\n            ```yaml\n                traefik.ingress.kubernetes.io/router.middlewares: longhorn-system-longhorn-auth@kubernetescrd\n            ```\n\n            Its important to note the namespace of the middleware, `longhorn-system` , before calling the middleware's name. This is to let the crd know where the middleware is located.\n\n* * *\n\n## Notes\n\n[According to the notes on Traefik & Kubernetes](https://doc.traefik.io/traefik/providers/kubernetes-crd/)\nwe first need to install the Resource Definitions and RBAC into `kubectl` by running the following commands:\n\n```shell\n# Install Traefik Resource Definitions:\nkubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v2.8/docs/content/reference/dynamic-configuration/kubernetes-crd-definition-v1.yml\n\n# Install RBAC for Traefik:\nkubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v2.8/docs/content/reference/dynamic-configuration/kubernetes-crd-rbac.yml\n\n```\n\nAfter this installation, we'll have a set of [Custom Resource Definitions](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\nwhich should have the following benefits:\n\n- The usage of `name` and `namespace` to refer to another Kubernetes resource.\n- The usage of [secret](https://kubernetes.io/docs/concepts/configuration/secret/) for sensitive data (TLS certificates and credentials).\n- The structure of the configuration.\n- The requirement to declare all the [definitions](https://doc.traefik.io/traefik/reference/dynamic-configuration/kubernetes-crd/#definitions).\n\nSee the list of CRDs in the dedicated [routing section](https://doc.traefik.io/traefik/routing/providers/kubernetes-crd/).\n\nThe biggest thing we need from this is the ability to add the [BasicAuth](https://doc.traefik.io/traefik/middlewares/http/basicauth/) plugin.\nThis plugin (which is what we tried to reference before with the `auth@file` line) uses an htpasswd password to block incoming traffic to the pod.\n\nThis will require setting up an IngressRoute (which is a specific Kubernetes resource added by the Traefik Resource Definitions) with settings to specify\nwhat the middlewares are. [Find more info on the Traefik Middlewares Here](https://doc.traefik.io/traefik/middlewares/overview/)\n\n* * *\n\n\n## Cloudflare\n\nThese are notes on integrating `Cloudflare` with `Traefik`, including automating some of the actions so that you may not have to repeat them.\n\n### Acme Docs\n\n[Official Docs](https://go-acme.github.io/lego/dns/cloudflare/#api-tokens)\n\nAccess the API Tokens directly from [Cloudflare Profile](https://dash.cloudflare.com/profile/api-tokens)\n\nCommon environmental variable names and their purpose:\n\n- `CF_API_EMAIL` - The Cloudflare account holder's email.\n- `CF_API_KEY` - The Cloudflare API key.\n- `CF_DNS_API_TOKEN` - The API token with `DNS:Edit` permission.\n- `CF_ZONE_API_TOKEN` - The API token with `Zone:Read` permission.\n","collection":"application","data":{"title":"Traefik","description":"A cloud native application proxy that utilizes a modern HTTP reverse-proxy and load balancer.","tags":["networking","lb"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1524419986249-348e8fa6ad4a?fit=crop&w=1400&h=700&q=75"}},{"id":"unity.mdx","slug":"unity","body":"\n## Unity\n\n- Unity is a cross-platform software engine that focuses on developing games, apps and animation for desktop, mobile, console and virtual reality platforms.\n- The primary scripting language for the engine is `C#` and can be extended through a various collection of libraries and plugins.\n\n## Header\n\n- Right click and create empty\n- Name it below : (Replace HeaderName with the name you would want)\n\n```shell\n---> HeaderName\n```\n\n* * *\n\n## WebGL\n\nA breakdown of WebGL for the Unity game engine!\n\n### WebGL Information\n\nWhen converting a project over to WebGL, there are a couple extremely important steps that you might have to take to prepare for an automated pipeline and distribution.\n\nThe most important step is to make sure that you have the HTML5/WebGL module for the specific Unity version installed and ready.\n\nAfter that check the resolution, an example would be 800 x 600 but you can set it to your project's desired scope.\n\nNext you want to make sure to check the box, `Run in background`, and save it. This should change the `runInBackground` inside of `ProjectSettings\\ProjectSettings.asset` from 0 (false) to 1 (true).\n\nFinally double check that you have the right compression methods enabled or in some cases, like Github Pages, disabled completely.\n\n* * *\n\n## Vuplex\n\nThis is a 3rd party plugin provider for Unity, that extends out the webview components for cross-platform compatibility through their own object-based library.\n\n### Vuplex Errors\n\nThese are reference points for common errors within the Vuplex libraries / eco-system.\n\n#### Heavy CPU Usage\n\nLoading multiple webview components within a single scene can cause a spike within the client's CPU/RAM, thus it is recommended to de-sync / destroy or de-activate any un-used Canvas. Furthermore, only activate the GameObject when the player is within a set proximity to the object through the Unity's Collider system via event triggers.\n\nAn example of this would be to declare the GameObject, add collision and then hook it a simple trigger script, like this:\n\n```c#\n\n    public GameObject webviewObject;                                                                            \n    [SerializeField] private bool EnablePlayerWebview;\n    \n    private void OnTriggerEnter(Collider other)\n    {    \n        if(other.CompareTag(\"Player\") && EnablePlayerWebview) { webviewObject.SetActive(true);   }\n\n    }\n\n    private void OnTriggerExit(Collider other)\n    {\n        Debug.Log(\"Exiting\");\n        webviewObject.SetActive(false);\n    } \n\n```\n\n#### Click and scroll not working : [Case 1]\n\nThere could be multiple reasons why click/scroll might not be functional, depending on the operating system, AR/VR tool kits and the Unity's input system.\nWhen defusing the situation, we recommend build multiple test cases with all components mapped out and then using `Debug.Log` to check through all the variables at play.\nWe been in situations where a foot of a humanoid object was not tagged as a `Player`, thus causing the whole collision engine to be off and not registering the functionality within a scene.\n\n11/30/2022 - We are currently experience this exact situation, so we will be updating these notes to fit accordingly to the issue.\n\n* * *\n\n## UCC\n\nUltimate Character Controller was the plugin of choice when doing RSDD aka rapid self-destructive development.\n\nOfficial Documentation [Link](https://opsive.com/support/documentation/ultimate-character-controller/). It is over 300 pages and covers the controller and its interaction within the unity environment.\n\nAccording to Opsive, their UCC is a professional and kinematic character controller that is designed for flexibility, modularity and performance; we consider it an \"AIO\" or \"All-In-One\" library.\n\n* * *\n\n### UCC URP\n\nGrab the invoice number from the plugin purchase and head over to [OPSive Downloads](https://opsive.com/downloads/) with it.\nAfter placing the invoice number into the system, it will give you download integrations for external plugins.\n\n* * *\n\n### UCC Asset Store\n\nOfficial [Asset Store](https://assetstore.unity.com/packages/tools/game-toolkits/ultimate-character-controller-233710).\nLast Release Date: 3.0.3 - Nov 24, 2022\n\n* * *\n\n### UCC Reference\n\n[Opsive Video Collection](https://opsive.com/videos/?pid=923)\n[First Person Character Creation](https://www.youtube.com/watch?v=EAuS_0OxyrA)\n\n* * *\n\n### UCC Character\n\nThe core of the UCC, Ultimate Character Controller, would be the Character model and its interactivity within the `Scene`, thus these notes are for referencing through the plugin and movement, collision, motion, gravity, abilities and more for the `Humanoid` / `Character`.\n\n* * *\n\n## UCCIS\n\nThe `3DUnity` gateway layer will utilize the `UCC Inventory System` , which we can refer to as `UCCIS`, is an inventory system that was designed by Opsive and extended by our `3DUnity`.\n\n### UCC Inventory\n\nThe `UCC Inventory` can be broken into modules, that we will refer to as:\n\n- Inventory\n- Item\n  - Action (Item)\n  - Object (Item)\n- Attributes\n- Currency\n- Crafting\n- Input\n\nThere are more modules within the system but v3 was released in late November 2022 and we still have to read through the notes/documentation && create test cases for each of the additional modules.\n\n#### UCCIS Attributes\n\nThe `Attributes` can be referenced throughout the `engine` and are designed to `override, inherit or modify` the value of another attribute; `Attributes` can be utilized to create variants (`Override`, `Inherit` or `Modify`) of Item Definitions.\n\nThe `Attributes` can be broken down into three variant types: (As referenced in the documentation)\n\n- Override: Overrides the `parent` attribute value of the given object.\n- Inherit: Inherits the `parent` attribute value of the given object.\n- Modify: Uses an expression to compute a value that is dependent on the “parent” attribute or any other attribute in the same collection.\n\n### UCCIS References\n\n[Asset Store](https://assetstore.unity.com/packages/tools/game-toolkits/ultimate-inventory-system-166053)\n[Inventory Docs](https://opsive.com/support/documentation/ultimate-inventory-system/)\n\nVideo Tutorials\n\n[Video Part 1](https://www.youtube.com/watch?v=-AqJ3-BXS70)\n[Video Part 2](https://www.youtube.com/watch?v=m0Z-wPFkM9w)\n\nThe two part video tutorial goes through a UCC / Inventory integration.\n\n* * *\n\n## Steam\n\nThese notes are still a work in progress, but I will try my best to continue to improve them as I am building out the Steam API for the Unity/React Project.\nOfficial [Repo](https://steamworks.github.io/installation/#unity-instructions)\n\n### Before\n\nIt seems that before you start to integrate SteamWorks / Steam API / SteamWorksNET , you need an active SteamWorks developer account. You can create the account [here](https://partner.steamgames.com/newpartner/?)\n\n`Legal Name`\n\nSteam Defines it as\n\n>This is really, really important to enter correctly. Carefully read all instructions below. You will be unable to release your product via Steam until this name matches all records.\n>The name you enter below must be the legal entity that owns or has rights to publish the game, software or video (\"content\") and is the legal entity that will be signing the Steam Distribution Agreement. The legal name you enter here must match the name as written on official documents with your bank and on United States IRS tax documents or foreign tax documents if applicable. You will need to enter this name again as your bank account holder and the legal name associated with a tax payer identification number in the following steps.\n>If you don’t have a company name and you are the sole owner of your content, please fill in your full name as the Legal Name and your own address as Street Address. If you co-own the content with other individuals, you must form a legal entity to own and receive payments for your content.\n>The Legal Name here is for internal use. If you have a DBA or 'friendly name' that you wish to show to customers on your store page, you will be able to enter that separately when creating your store page.\n\nThis is an extremely important step, we advise that you consult with your legal parties if there are any major issues.\n\nWe recommend that, if you are a US Citizen, have all our personal information (Tax, Bank, KYC, ect...) ready before completing the application. Furthermore, there is a $100 fee for the application.\n\n### After\n\nWell we applied as of 11/23/2022 , so we will wait until everything is confirmed and then move forward with this.\n\nOkay so we been approved, now you should have 1 application credit in your Steamworks profile! This is where you then create your application, using that application credit that you paid $100 for!\n\nPlace your application name and then go through the form, it will then spit out some interesting variables:\n\n>Requesting AppID For: KBVE.com RogueJester\n>Created package \"KBVE.com RogueJester Developer Comp\" with ID 802XXX\n>Created package \"KBVE.com RogueJester for Beta Testing\" with ID 802XXX\n>Created package \"KBVE.com RogueJester\" with ID 802XXX\n>Added auto-grant to publisher *XXX\n>Created store item '518XXX'\n>Created store package for store item '518XXX'\n\nYou should keep this information safe and as a reference step.\n\n* * *\n\n## Plugins\n\n- Collection of plugins for Unity game engine.\n\n### React\n\n- For React and Unity integration, we recommend going to our [React](https://kbve.com/application/javascript/#react) application page.\n\n### Steam Plugin\n\nWe moved the Steam into their own [notes](https://kbve.com/application/unity/#steam)\n\n### SimpleJSON\n\n- SimpleJSON is a plugin for JSON parsing in C#.\n- Official [Repo](https://github.com/Bunny83/SimpleJSON)\n\n### Modular AI\n\n- Modular AI helps design the behavior of GameObjects within Unity.\n- Official [Repo](https://github.com/Kitbashery/Modular-AI)\n\n### Hey Area Object Spawner\n\n- A simple tool that helps procedural generation of objects within an area.\n- Official [Repo](https://github.com/JahnStar/Hey-Area-Object-Spawner)\n\n### Hierarchy 2\n\n- Hierarchy 2 helps organize the Unity UI.\n- Official Asset [Store](https://assetstore.unity.com/packages/tools/utilities/hierarchy-2-166483)\n\n### Premium\n\n- Premium plugins that have additional license or costs with them.\n\n### OneJS\n\n- Interpol between Javascript and Unity through JINT\n- This plugin is not open source but rather a private engine.\n\n### Webview\n\nUnity plugins that focus on webview by providing abstract layers that extend to controllers.\n\n### UniWebView\n\n- Adding Webview for iOS/Android can be easier through UniWebView, which is an open source web view component for mobile platforms.\n- Official [Repo](https://docs.uniwebview.com/api/)\n\n### Vuplex Plugin\n\nA commercial plugin that extends WebView components across all platforms, with major focus on AR/VR development kits for Oculus, Hololens and more.\nNotes on the [Vuplex](https://kbve.com/application/unity/#vuplex)\n\n* * *\n\n## Pipeline\n\nFor Unity Pipeline we recommend going to our [git](https://kbve.com/application/git/) for information regarding setting up the CI/CD.\n\n## Unity Notes\n\n### Notes\n\n- Unity follows a duel release structure for their engine, a `latest` engine build and a `LTS` engine.\n- We recommend using the `LTS` as it has `Long Term Support`, which the company states for about 2 years, whereas the `latest` does not have any extended support.\n\n## Unity Multiplayer\n\n- Colyseus.io seems like the first engine of choice that we might use.\n  - Github [Repo](https://github.com/colyseus/colyseus)\n  - Colyseus.io [Docs](https://docs.colyseus.io/colyseus/)\n\n- Reference Links\n  - Chowdera [1](https://chowdera.com/2021/05/20210512110823582J.html)\n  - S1H [2](https://blog.s1h.org/colyseus-multiplayer-game/)\n\n## Error\n\n- Common errors that users might face when working with Unity. This error log is meant to help keep track and may save some future developers a lot of time.\n\n### Error WebGL-000001FEA50EC410\n\n- ```shell\n    [.WebGL-000001FEA50EC410] GL_INVALID_FRAMEBUFFER_OPERATION: Draw framebuffer is incomplete\n    ```\n\n  - Solution: Turn on post processing on the Main Camera.\n\n### Error libil2cpp ERROR: Could not open Il2CppData/\n\nCurrently: There might be an issue when directly loading the Git LFS, so we will reference it via Github's media server.\nGit Notes can be found [here](https://kbve.com/application/git)\n\n### Error Dirty Branch\n\nThis will be a common error that you will see throughout `CI/CD` and comes from various issues, it can be from the wrong `guid` / `Seralization` or broken `ProjectSettings.asset`\n\nYou can ignore the dirty branch errors by using `allowDirtyBuild: true` within the `game-ci`, however this may cause problems down the line when the build gets more complex and additional platforms i.e `WebGl`, `Xbox`, ect...\n\n## Corgi\n\nThese are KBVE notes and references for the `Corgi Engine` that was developed by More Mountains. Please note that the core of the Corgi Engine is a private / premium plugin for the Unity Engine, thus parts of our codebase / references will not work `out of the box`, as you will have to install the latest engine from the Unity Asset store.\n\n### Corgi API\n\n### Corgi Documentation\n\n### Corgi Examples\n\n## Unity Canvas\n\nThe Canvas is a GameObject within Unity that extends the UI elements and utilizes the EventSystem / Scene View.\n\n## Unity Assets\n\n- Unity Assets are a collection of media files.\n\n## 2D Assets\n\nThis is a collection of 2D assets that can be a great resource / reference for anyone looking to make a 2D game. We could migrate the 2D assets into their own reference later down the line.\n\n### PixelFrog\n\nOfficial [Itch](https://pixelfrog-assets.itch.io/)\n\nTreasure Hunters [Download](https://pixelfrog-assets.itch.io/treasure-hunters)\nKings and Pings [Download](https://pixelfrog-assets.itch.io/kings-and-pigs)\nPixel Adventure [Download](https://pixelfrog-assets.itch.io/pixel-adventure-1)\nPirate Bomb [Download](https://pixelfrog-assets.itch.io/pirate-bomb)\n\n## 2D\n\nThese are the notes for Unity's 2D engine and/or projects related to the 2D development cycle.\n\n### Corgi Engine\n\nWe are currently test casing the corgi engine as the base for our 2D engine and then going to integrate it with our 2DUnity. As of early December 2022, we are test casing the pipeline with the engine as an underlay and restructuring our `2DUnity` as a gateway layer, a similar setup to our `3DUnity` and `UCC`.\n\n### Corki Namespace\n\nThe `Corki` namespace is a KBVE extension of the `Corgi` namespace, adding custom gateway layers that make it easier to infer and interpolate among different APIs.\n\n## 2D Examples\n\nThe list below are open source projects that use Unity as their base for 2D/Retro style games.\n\n### Newbark\n\nOfficial [Repo](https://github.com/itsjavi/newbark-unity)\n\nItsjavi created an amazing open source proof-of-concept version of classic Pokemon (Red/Blue/Gold) that has been updated to Unity 2021 and has URP. It should be noted that there assets that might be infringing on intellectual property of Nintendo/Game Freak.\nOn a positive note, upon looking through his repo, I did stumble across a github bot known as [ImgBot](https://kbve.com/application/git/#imgbot), which provides image optimization via Git pulls.\n\nThe project uses: 2021.1.6f1 as the Unity Version and there seems to not include any pipeline/workflow, which might be because of the copyright issues.\nThe project also has [URP / Universal Render Pipeline](https://kbve.com/application/unity/#urp)\n\nI suppose it be interesting to take a look at their combat system, since the biggest issue that I see would be the usage of copyrighted material, but if you were to swap them out, then there might be a case to continue and `enhance` the repo? If anyone might be down to do this, please reach out to h0lybyte.\n\n### Kailius\n\nOfficial [Repo](https://github.com/Walkator/kailius)\n\nThis was another open source 2D repo that sparked my interest because it was built for the phone! It is a great reference point for a game written for Android by going through `input design` from dual perspective of UX/UI and internal scripting.\n\n#### Minor 2Ds\n\n[SpaceWalk Official Repo](https://github.com/Angel1841/Space-Walk)\n[FinalProject UnityW2022](https://github.com/DuncanBH/FinalPlatformerProject)\n","collection":"application","data":{"title":"Unity","description":"A 3D Game and App Engine to build cross platform software.","tags":["gaming","engine"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1519669556878-63bdad8a1a49?fit=crop&w=1400&h=700&q=75"}},{"id":"void.mdx","slug":"void","body":"\n## VOID\n\n- Virtualized Object Intelligence Daemon, or VOID, is an operator application that manages servers, nested machines and clustered botnets within an eco-system.\n  - Linux\n    - `void_install_ubuntu.sh` - (chmod 777) - Installation for Ubuntu 18+\n    - `void_install_debian.sh` - (chmod 777) - Installation for Debian 9+\n  - Windows\n    - `void_install_win11.exe` - (admin privilege) - Install for Windows 11\n  - Mac\n    - Mac M1 / M2* has an ARM based system, so it might have to be isolated from the intel macs.\n    - Expanding upon brew might be a better course for Macs*\n- Environs are entities that help balance and regulate the digital environmental.\n\n## TR33\n\n- `tr33` - (environ) - a collection of timers that handle micro tasks on the host machine.\n  - `tr33._04` - v4 is stable for Ubuntu 22 LTS, Debian 9, Windows 10/11.  \n    - `tr33._04.nginx.1_22` - Nginx\n    - `tr33._04.apache.1` - Disabled.\n  - `tr33._05YAML_.` - v5 is unstable but utilizes YAML, slated for deprecation by Q3 of 2024.\n  - `tr33._06JSON_.` - v6 is unstable but utilizes a JSON-based API for commands, slated for deprecation by Q4 of 2025.0\n  - `tr33._01`  - Deprecated - A rootkit that was designed and based upon various viruses.\n  - `tr33._02` - Deprecated.\n  - `tr33._03` - Deprecated.\n\n## S33D\n\n- `s33d` - (environ) - an application or library that expands upon torrent data seeding.\n  - `s33d._dna.` - commands that the host computer must run to enable specific future applications.\n    - `s33d._dna.WebRTC.1_3` - Enables WebRTC.\n  - `s33d._nfc.` - Compressed information that can be stored inside NFC. The format will take about 64 bytes.\n    - `68 74 74 70 73 3a 2f 2f 6e 2e 6b 62 76 65 2e 63 6f 6d 2f 64 6e 61 2f` - 23 bytes for the generic/default location of the seed, with 40 bytes left over for additional information regarding the application(s).\n\n## BL0CK\n\n- `bl0ck` - micro storage for host.\n  - `bl0ck.B64AES.` - Based 64 - AES compressed data block.\n  - `bl0ck.chain._` - Micro blockchain for the void system(s).\n\n## R00T\n\n- `r00t` - (environ) - an embed that sits on-top of the operating system.\n  - `r00t` - Disabled as of `tr33._02` because the design induced significant flaws and exploits; uncle ben does not approve of such power for any man or s\n","collection":"application","data":{"title":"VOID","description":"Virtualization soft scripting for automation.","tags":["php","script"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1537158345907-c4fb34477bd6?fit=crop&w=1400&h=700&q=75"}},{"id":"watchtower.mdx","slug":"watchtower","body":"\nimport Github from \"@c/Action/Github/Github.astro\";\nexport const components = { github: Github }; \n\n## Watchtower\n\n* * *\n\n## Install\n\n<Github\n  src=\"data/watchtower/docker-compose.yml\"\n  description=\"This is a docker compose we made.\"\n/> \n\n## Notifications\n\nIncase you need WatchTower to send Notifications, here is an example command that sets the environmental variables:\n\n\n```shell\ndocker run -d \\\n  --name watchtower \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -e WATCHTOWER_NOTIFICATIONS=email \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_FROM=fromaddress@gmail.com \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_TO=toaddress@gmail.com \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER=smtp.gmail.com \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=587 \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER=fromaddress@gmail.com \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD=app_password \\\n  -e WATCHTOWER_NOTIFICATION_EMAIL_DELAY=2 \\\n  containrrr/watchtower\n```\n","collection":"application","data":{"title":"Watchtower","description":"A monitioring tool for automating Docker containers based upon image updates.","tags":["technology","vm","security","docker"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1602616213661-d1f469cd5a95?fit=crop&w=1400&h=700&q=75"}},{"id":"webserver.mdx","slug":"webserver","body":"## WebServer\n\n### Nginx\n\n### Apache\n\n## Tools\n\n### SpeedTest\n\n- Google's PageSpeed Insight\n  - [Official WebTool Location](https://pagespeed.web.dev/)\n    - The tool tests for both mobile and desktop, with couple options on the side.\n\n- TechEmpower Web Framework List\n  - [Official WebFrame](https://www.techempower.com/benchmarks/#section=data-r21)\n    - Performance is isolated by rounds, done annually.\n\n### CRT\n\nFinding the latest collection of certs for a domain.\n\n[CRT](https://crt.sh/?q=kbve.com&showSQL=Y)\n\n## Robots.txt\n\n- The purpose of this file to help the webmaster(s) provide pathways for bots to navigate the domain and internal sub-domains.\n","collection":"application","data":{"title":"WebServer","description":"Software that accepts requests via the HTTP/HTTPS protocol.","tags":["software","protocol"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1492515114975-b062d1a270ae?fit=crop&w=1400&h=700&q=75"}},{"id":"wireguard.mdx","slug":"wireguard","body":"\nimport Github from \"@c/Action/Github/Github.astro\";\nexport const components = { github: Github };\n\n\n## Wireguard\n\n* * *\n\n## Install\n\n- Docker Compose\n  - `<Github src=\"data/wireguard/docker-compose.yml\" description=\"This is a docker compose for wireguard.\" />`\n\n- Ubuntu Installation Guide\n  - Core Pre-Installation\n    - Make sure your docker install is setup! If you need more information, please visit our Docker application page.\n    - Check your firewall, are you using `ufw` , `iptables` or `nftables`\n  - Firewall\n    - Wireguard will be operating on the `UDP` port of `51820`.\n    - For: `ufw`\n      - To enable the port through `ufw` run `sudo allow 51821/udp`\n\n## Netmaker\n\n- Netmaker is a Wireguard automation application that handles self-hosted homelabs to small business / enterprise networking.\n- [Official Github Repo](https://github.com/gravitl/netmaker)\n\n## Netmaker Install\n\n- Advance install for netmaker allows the setup of a highly available installation within Kubernetes through helm.\n- The *default* settings may not install `wireguard` at the kernel level (for security reasons) and default to Postgres for storage.\n  - Not having kernel level wireguard may cause performance drops and they recommend that you install wireguard before beginning.\n- Helm Install Commands:\n\n  - ```shell\n    helm repo add netmaker https://gravitl.github.io/netmaker-helm/\n    helm repo update\n    ```\n  \n  - If you do not have `helm` or `kubernetes` setup, we recommend you visit our [kubernetes setup](https://kbve.com/application/k8s).\n- The storage of the certificates will be an issue for this netmaker cluster, they recommend two types of storage classes:\n  - `RWO` - `Read Write Once` - Storage instance where only a single node is allowed to access the storage volume at a time for read and write access.\n  - `RWX` - `Read Write Many` - Storage instance where many nodes can concurrently read and write to the storage volume.\n","collection":"application","data":{"title":"Wireguard","description":"A open source communication protocol that implements encrypted virtual private networks.","tags":["vpn","host","security"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1649429398909-db7ae841c386?fit=crop&w=1400&h=700&q=75"}},{"id":"zsh.mdx","slug":"zsh","body":"\n## Useful Links\n\n- [ZSH Shell Official Page](https://www.zsh.org/)\n- [Oh My Zsh Official Page](https://ohmyz.sh/)\n- [Powerlevel10K Repository](https://github.com/romkatv/powerlevel10k)\n- [One of the Best Tutorials by dev.to (Dec 2020)](https://dev.to/abdfnx/oh-my-zsh-powerlevel10k-cool-terminal-1no0)\n","collection":"application","data":{"title":"Oh My Zsh","description":"Oh My Zsh is a delightful, open source, community-driven framework for managing your Zsh configuration. It comes bundled with thousands of helpful functions, helpers, plugins, themes.\n","tags":["technology","terminal","cli","theming","rice"],"author":"KBVE Team","img":"https://images.unsplash.com/photo-1607877361964-bf792b65e593?fit=crop&w=1400&h=700&q=75"}}]